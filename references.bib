@article{smith2023,
  author={Smith, John},
  title={A Comprehensive Study on Artificial Intelligence},
  journal={Journal of Computer Science},
  year={2023},
  volume={45},
  number={3},
  pages={201-215},
}

@book{jones2022,
  author={Jones, Emily},
  title={The History of Ancient Civilizations},
  publisher={Academic Press},
  year={2022},
  address={New York},
  edition={2nd},
  isbn={978-0-12-345678-9},
}

@article{lee2023,
  author={Lee, Sarah and Kim, David},
  title={Advancements in Renewable Energy Technologies},
  journal={Renewable Energy Reviews},
  year={2023},
  volume={78},
  number={4},
  pages={501-515},
}

@book{adams2021,
  author={Adams, Michael},
  title={The Art of Creative Writing},
  publisher={Writer's Press},
  year={2021},
  address={London},
  isbn={978-1-234567-89-0},
}

@article{wilson2023,
  author={Wilson, Laura},
  title={Recent Discoveries in Astrophysics},
  journal={Astrophysical Journal},
  year={2023},
  volume={635},
  number={2},
  pages={315-328},
}

@book{martinez2022,
  author={Martinez, Carlos},
  title={The Economics of Globalization},
  publisher={Harvard University Press},
  year={2022},
  address={Cambridge},
  isbn={978-0-9876543-21-0},
}

@article{brown2023,
  author={Brown, Jennifer and Clark, Robert},
  title={The Impact of Climate Change on Biodiversity},
  journal={Environmental Science Quarterly},
  year={2023},
  volume={22},
  number={1},
  pages={45-58},
}

@book{wright2021,
  author={Wright, Susan},
  title={Understanding Psychology: A Comprehensive Guide},
  publisher={Oxford University Press},
  year={2021},
  address={Oxford},
  isbn={978-0-876543-21-9},
}

@article{turner2023,
  author={Turner, James and Parker, Elizabeth},
  title={Recent Advances in Nanotechnology},
  journal={Nano Letters},
  year={2023},
  volume={12},
  number={5},
  pages={601-612},
}

@book{phillips2022,
  author={Phillips, Robert},
  title={Ancient Mythology and Its Relevance Today},
  publisher={Mythos Publications},
  year={2022},
  address={San Francisco},
  isbn={978-0-56789-012-3},
}


@article{Chen2023Perspectives,
	author={Valerie Chen and Umang Bhatt and Hoda Heidari and Adrian Weller and Ameet Talwalkar},
	doi={https://doi.org/10.1016/j.patter.2023.100780},
	issn={2666-3899},
	journal={Patterns},
	number={7},
	pages={100780},
	title={Perspectives on incorporating expert feedback into model updates},
	volume={4},
	year={2023},
}


@article{bradley-terry-model,
 ISSN={00063444},
 URL={http://www.jstor.org/stable/2334029},
 author={Ralph Allan Bradley and Milton E. Terry},
 journal={Biometrika},
 number={3/4},
 pages={324--345},
 publisher={[Oxford University Press, Biometrika Trust]},
 title={Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons},
 urldate={2023-10-09},
 volume={39},
 year={1952}
}



@inproceedings{ideal_point,
	author={Jamieson, Kevin G and Nowak, Robert},
	booktitle={Advances in Neural Information Processing Systems},
	editor={J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
	publisher={Curran Associates, Inc.},
	title={Active Ranking using Pairwise Comparisons},
	url={https://proceedings.neurips.cc/paper_files/paper/2011/file/6c14da109e294d1e8155be8aa4b1ce8e-Paper.pdf},
	volume={24},
	year={2011},
	bdsk-url-1={https://proceedings.neurips.cc/paper_files/paper/2011/file/6c14da109e294d1e8155be8aa4b1ce8e-Paper.pdf}}


@INPROCEEDINGS{tatli2022distancepreferences,
  author={Tatli, Gokcan and Nowak, Rob and Vinayak, Ramya Korlakai},
  booktitle={2022 58th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Learning Preference Distributions From Distance Measurements}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/Allerton49937.2022.9929404}}


@misc{rafailov2023direct,
    title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
    author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
    year={2023},
    eprint={2305.18290},
    archivePrefix={arXiv},
}


@inproceedings{huber1976ideal,
  title={Ideal Point Models of Preference},
  author={Huber, Joel},
  booktitle={Advances in Consumer Research},
  volume={03},
  pages={138--142},
  year={1976},
  organization={Association for Consumer Research}
}


@MISC{idealpoints,
  author="Greiner, James",
  title="Ideal Points",
  howpublished="Harvard IQSS Blog",
  month="October",
  year="2005",
  url="https://blogs.iq.harvard.edu/ideal_points_1"
}



@article{zermelo1929iteration,
    author={Zermelo, E. },
    date={1929/12/01},
    date-added={2023-10-09 16:56:52 -0700},
    date-modified={2023-10-09 16:56:52 -0700},
    doi={10.1007/BF01180541},
    id={Zermelo1929},
    isbn={1432-1823},
    journal={Mathematische Zeitschrift},
    number={1},
    pages={436--460},
    title={Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung},
    url={https://doi.org/10.1007/BF01180541},
    volume={29},
    year={1929},
    bdsk-url-1={https://doi.org/10.1007/BF01180541},
}

@misc{Radford2018GPT,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{plackett_luce,
 ISSN={00359254, 14679876},
 URL={http://www.jstor.org/stable/2346567},
 abstract={A probability distribution is defined over the r! permutations of r objects in such a way as to incorporate up to r! - 1 parameters. Problems of estimation and testing are considered. The results are applied to data on voting at elections and beanstores.},
 author={R. L. Plackett},
 journal={Journal of the Royal Statistical Society. Series C (Applied Statistics)},
 number={2},
 pages={193--202},
 publisher={[Wiley, Royal Statistical Society]},
 title={The Analysis of Permutations},
 urldate={2023-10-10},
 volume={24},
 year={1975}
}



@misc{christiano2023deep,
      title={Deep reinforcement learning from human preferences}, 
      author={Paul Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
      year={2023},
      eprint={1706.03741},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{paszke2019pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{recommender_systems,
  title={A systematic review and research perspective on recommender systems},
  author={Deepjyoti Roy and Mala Dutta},
  journal={Journal of Big Data},
  year={2022},
  volume={9},
  pages={1-36},
  url={https://api.semanticscholar.org/CorpusID:248508374}
}

@book{book_estimation_casella,
  title={Statistical Inference},
  author={George Casella and Roger L. Berger},
  year={1990},
  url={https://api.semanticscholar.org/CorpusID:125727004},
  publisher={Springer},
}

@book{book_estimation_bock,
    title={Model Based Parameter Estimation: Theory and Applications},
    author={Hans Georg Bock and Thomas Carraro and Willi J{\"a}ger and Stefan K{\"o}rkel and Rolf Rannacher and Johannes P. Schl{\"o}der},
    year={2015},
    url={https://api.semanticscholar.org/CorpusID:60333071},
    publisher={Springer},
}

 @article{auer_cesa-bianchi_fischer_2002,  title={Finite-time Analysis of the Multiarmed Bandit Problem},  journal={Machine Learning}, volume={47},  DOI={10.1023/A:1013689704352},  number={2},  publisher={Kluwer Academic Publishers},  author={Auer, Peter and Cesa-Bianchi, Nicolò and Fischer, Paul},  year={2002},  month={May} }


@article{LAI19854,
	author = {T.L Lai and Herbert Robbins},
	doi = {https://doi.org/10.1016/0196-8858(85)90002-8},
	issn = {0196-8858},
	journal = {Advances in Applied Mathematics},
	number = {1},
	pages = {4-22},
	title = {Asymptotically efficient adaptive allocation rules},
	url = {https://www.sciencedirect.com/science/article/pii/0196885885900028},
	volume = {6},
	year = {1985},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/0196885885900028},
	bdsk-url-2 = {https://doi.org/10.1016/0196-8858(85)90002-8}}

@misc{mansour2019bayesianincentivecompatiblebanditexploration,
      title={Bayesian Incentive-Compatible Bandit Exploration}, 
      author={Yishay Mansour and Aleksandrs Slivkins and Vasilis Syrgkanis},
      year={2019},
      eprint={1502.04147},
      archivePrefix={arXiv},
      primaryClass={cs.GT},
      url={https://arxiv.org/abs/1502.04147}, 
}

@misc{mansour2021bayesianexplorationincentivizingexploration,
      title={Bayesian Exploration: Incentivizing Exploration in Bayesian Games}, 
      author={Yishay Mansour and Aleksandrs Slivkins and Vasilis Syrgkanis and Zhiwei Steven Wu},
      year={2021},
      eprint={1602.07570},
      archivePrefix={arXiv},
      primaryClass={cs.GT},
      url={https://arxiv.org/abs/1602.07570}, 
}

@misc{russo2015informationtheoreticanalysisthompsonsampling,
      title={An Information-Theoretic Analysis of Thompson Sampling}, 
      author={Daniel Russo and Benjamin Van Roy},
      year={2015},
      eprint={1403.5341},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1403.5341}, 
}

@misc{xu2024principledpreferentialbayesianoptimization,
      title={Principled Preferential Bayesian Optimization}, 
      author={Wenjie Xu and Wenbin Wang and Yuning Jiang and Bratislav Svetozarevic and Colin N. Jones},
      year={2024},
      eprint={2402.05367},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.05367}, 
}

@misc{astudillo2023qeubodecisiontheoreticacquisitionfunction,
      title={qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization}, 
      author={Raul Astudillo and Zhiyuan Jerry Lin and Eytan Bakshy and Peter I. Frazier},
      year={2023},
      eprint={2303.15746},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.15746}, 
}

@misc{wu2018parallelknowledgegradientmethod,
      title={The Parallel Knowledge Gradient Method for Batch Bayesian Optimization}, 
      author={Jian Wu and Peter I. Frazier},
      year={2018},
      eprint={1606.04414},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1606.04414}, 
}

 @article{kahneman_tversky_1979,  title={Prospect theory: analysis of decision under risk},  volume={47},  DOI={10.2307/1914185},  number={2},  publisher={John Wiley and Sons},  author={Kahneman, Daniel and Tversky, Amos},  year={1979},  month={Jan} , journal={Econometrica}}

@article{kongschoenebeck2019,
author = {Kong, Yuqing and Schoenebeck, Grant},
title = {An Information Theoretic Framework For Designing Information Elicitation Mechanisms That Reward Truth-telling},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {2167-8375},
url = {https://doi.org/10.1145/3296670},
doi = {10.1145/3296670},
journal = {ACM Trans. Econ. Comput.},
month = {jan},
articleno = {2},
numpages = {33},
}

@article{gradient_descent,
  title={An overview of gradient descent optimization algorithms},
  author={Sebastian Ruder},
  journal={ArXiv},
  year={2016},
  volume={abs/1609.04747},
  url={https://api.semanticscholar.org/CorpusID:17485266}
}

@book{suttonrl,
author={Sutton, Richard S. and Barto, Andrew G.},
title={Reinforcement Learning: An Introduction},
year={2018},
isbn={0262039249},
publisher={A Bradford Book},
address={Cambridge, MA, USA},
abstract={The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@book{dpbellman,
author={Richard E Bellman},
title={Dynamic programming.},
year={1957},
publisher={Princeton University Press},
address={Princeton, NJ, USA},
abstract={The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

@article{Watkins1992,
  abstract={Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  added-at={2020-01-01T20:16:30.000+0100},
  author={Watkins, Christopher J. C. H. and Dayan, Peter},
  biburl={https://www.bibsonomy.org/bibtex/2416ac9f845c6ccea5a7eacee4dedead8/lanteunis},
  day=01,
  doi={10.1007/BF00992698},
  interhash={a4436f9e14335d677f156049cb798253},
  intrahash={416ac9f845c6ccea5a7eacee4dedead8},
  issn={1573-0565},
  journal={Machine Learning},
  keywords={DRLAlgoComparison q-learning reinforcement_learning},
  month=may,
  number=3,
  pages={279--292},
  timestamp={2020-01-01T20:16:30.000+0100},
  title={Q-learning},
  url={https://doi.org/10.1007/BF00992698},
  volume=8,
  year=1992
}

@misc{levine2018reinforcement,
      title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}, 
      author={Sergey Levine},
      year={2018},
      eprint={1805.00909},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@phdthesis{pomdpdrake,
    author={Drake, Alvin},
    year={2005},
    month={08},
    pages={},
    title={Observation of a Markov process through a noisy channel},
    school={MIT},
}

@inproceedings{ziebart2008maximum,
   author={Brian D. Ziebart and Andrew Maas 
            and J. Andrew Bagnell and Anind K. Dey},
   title={Maximum Entropy Inverse Reinforcement Learning},
   year={2008},
   booktitle={Proc. AAAI},
   pages={1433--1438}
}

@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774},
  url={https://api.semanticscholar.org/CorpusID:257532815}
}

@misc{shah2019feasibility,
      title={On the Feasibility of Learning, Rather than Assuming, Human Biases for Reward Inference}, 
      author={Rohin Shah and Noah Gundotra and Pieter Abbeel and Anca D. Dragan},
      year={2019},
      eprint={1906.09624},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{abeelirl,
author={Abbeel, Pieter and Ng, Andrew Y.},
title={Apprenticeship Learning via Inverse Reinforcement Learning},
year={2004},
isbn={1581138385},
publisher={Association for Computing Machinery},
address={New York, NY, USA},
url={https://doi.org/10.1145/1015330.1015430},
doi={10.1145/1015330.1015430},
abstract={We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using "inverse reinforcement learning" to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function.},
booktitle={Proceedings of the Twenty-First International Conference on Machine Learning},
pages={1},
location={Banff, Alberta, Canada},
series={ICML '04}
}

@misc{ibarz2018reward,
      title={Reward learning from human preferences and demonstrations in Atari}, 
      author={Borja Ibarz and Jan Leike and Tobias Pohlen and Geoffrey Irving and Shane Legg and Dario Amodei},
      year={2018},
      eprint={1811.06521},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{chan2021humanirrationalitybadgood,
      title={Human irrationality: both bad and good for reward inference}, 
      author={Lawrence Chan and Andrew Critch and Anca Dragan},
      year={2021},
      eprint={2111.06956},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.06956}, 
}
@misc{mnih2013playing,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{Lichtenstein_Slovic_2006, author={Sarah Lichtenstein and Paul Slovic}, place={Cambridge}, title={The Construction of Preference}, publisher={Cambridge University Press}, year={2006}}

@misc{pilat_sekoul_2021,
  author = {Dan Pilat and Sekoul Krastev},
  title = {Distinction bias},
  year = {2021},
  publisher = {The Decision Lab},
  url = {https://thedecisionlab.com/biases/distinction-bias},
  urldate = {2024-07-10}
}

@misc{haarnoja2017reinforcement,
      title={Reinforcement Learning with Deep Energy-Based Policies}, 
      author={Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine},
      year={2017},
      eprint={1702.08165},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{liu2019stein,
      title={Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm}, 
      author={Qiang Liu and Dilin Wang},
      year={2019},
      eprint={1608.04471},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{hejna2023inverse,
      title={Inverse Preference Learning: Preference-based RL without a Reward Function}, 
      author={Joey Hejna and Dorsa Sadigh},
      year={2023},
      eprint={2305.15363},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Ghosal_Zurek_Brown_Dragan_2023, title={The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types}, volume={37}, url={https://ojs.aaai.org/index.php/AAAI/article/view/25740}, DOI={10.1609/aaai.v37i5.25740}, abstractNote={When inferring reward functions from human behavior (be it demonstrations, comparisons, physical corrections, or e-stops), it has proven useful to model the human as making noisy-rational choices, with a &quot;rationality coefficient&quot; capturing how much noise or entropy we expect to see in the human behavior. Prior work typically sets the rationality level to a constant value, regardless of the type, or quality, of human feedback. However, in many settings, giving one type of feedback (e.g. a demonstration) may be much more difficult than a different type of feedback (e.g. answering a comparison query). Thus, we expect to see more or less noise depending on the type of human feedback. In this work, we advocate that grounding the rationality coefficient in real data for each feedback type, rather than assuming a default value, has a significant positive effect on reward learning. We test this in both simulated experiments and in a user study with real human feedback. We find that overestimating human rationality can have dire effects on reward learning accuracy and regret. We also find that fitting the rationality coefficient to human data enables better reward learning, even when the human deviates significantly from the noisy-rational choice model due to systematic biases. Further, we find that the rationality level affects the informativeness of each feedback type: surprisingly, demonstrations are not always the most informative---when the human acts very suboptimally, comparisons actually become more informative, even when the rationality level is the same for both. Ultimately, our results emphasize the importance and advantage of paying attention to the assumed human-rationality-level, especially when agents actively learn from multiple types of human feedback.}, number={5}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ghosal, Gaurav R. and Zurek, Matthew and Brown, Daniel S. and Dragan, Anca D.}, year={2023}, month={Jun.}, pages={5983-5992} }

@article{glynnpg,
author={Glynn, Peter W.},
title={Likelihood Ratio Gradient Estimation for Stochastic Systems},
year={1990},
issue_date={Oct. 1990},
publisher={Association for Computing Machinery},
address={New York, NY, USA},
volume={33},
number={10},
issn={0001-0782},
url={https://doi.org/10.1145/84537.84552},
doi={10.1145/84537.84552},
abstract={Consider a computer system having a CPU that feeds jobs to two input/output (I/O) devices having different speeds. Let θ be the fraction of jobs routed to the first I/O device, so that 1 - θ is the fraction routed to the second. Suppose that α=α(θ) is the steady-sate amount of time that a job spends in the system. Given that θ is a decision variable, a designer might wish to minimize α(θ) over θ. Since α(·) is typically difficult to evaluate analytically, Monte Carlo optimization is an attractive methodology. By analogy with deterministic mathematical programming, efficient Monte Carlo gradient estimation is an important ingredient of simulation-based optimization algorithms. As a consequence, gradient estimation has recently attracted considerable attention in the simulation community. It is our goal, in this article, to describe one efficient method for estimating gradients in the Monte Carlo setting, namely the likelihood ratio method (also known as the efficient score method). This technique has been previously described (in less general settings than those developed in this article) in [6, 16, 18, 21]. An alternative gradient estimation procedure is infinitesimal perturbation analysis; see [11, 12] for an introduction. While it is typically more difficult to apply to a given application than the likelihood ratio technique of interest here, it often turns out to be statistically more accurate.In this article, we first describe two important problems which motivate our study of efficient gradient estimation algorithms. Next, we will present the likelihood ratio gradient estimator in a general setting in which the essential idea is most transparent. The section that follows then specializes the estimator to discrete-time stochastic processes. We derive likelihood-ratio-gradient estimators for both time-homogeneous and non-time homogeneous discrete-time Markov chains. Later, we discuss likelihood ratio gradient estimation in continuous time. As examples of our analysis, we present the gradient estimators for time-homogeneous continuous-time Markov chains; non-time homogeneous continuous-time Markov chains; semi-Markov processes; and generalized semi-Markov processes. (The analysis throughout these sections assumes the performance measure that defines α(θ) corresponds to a terminating simulation.) Finally, we conclude the article with a brief discussion of the basic issues that arise in extending the likelihood ratio gradient estimator to steady-state performance measures.},
journal={Commun. ACM},
month={oct},
pages={75–84},
numpages={10}
}

@misc{doersch2021tutorial,
      title={Tutorial on Variational Autoencoders}, 
      author={Carl Doersch},
      year={2021},
      eprint={1606.05908},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{hejna2023contrastive,
      title={Contrastive Preference Learning: Learning from Human Feedback without RL}, 
      author={Joey Hejna and Rafael Rafailov and Harshit Sikchi and Chelsea Finn and Scott Niekum and W. Bradley Knox and Dorsa Sadigh},
      year={2023},
      eprint={2310.13639},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{tunstall2023zephyr,
  title={ZEPHYR: DIRECT DISTILLATION OF LM ALIGNMENT},
  author={Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Clementine and Habib, Nathan and Sarrazin, Nathan and Sanseviero, Omar and Rush, Alexander M. and Wolf, Thomas},
  journal={arXiv preprint arXiv:2310.16944},
  year={2023},
  url={https://arxiv.org/pdf/2310.16944v1.pdf},
  note={Available from HuggingFace at: \url{https://huggingface.co/HuggingFaceH4}},
  email={lewis@huggingface.co},
  team={The H4 (Helpful, Honest, Harmless, Huggy) Team}
}

@misc{haarnoja2019soft,
      title={Soft Actor-Critic Algorithms and Applications}, 
      author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
      year={2019},
      eprint={1812.05905},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{BT,
 ISSN={00063444},
 URL={http://www.jstor.org/stable/2334029},
 author={Ralph Allan Bradley and Milton E. Terry},
 journal={Biometrika},
 number={3/4},
 pages={324--345},
 publisher={[Oxford University Press, Biometrika Trust]},
 title={Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons},
 urldate={2023-11-03},
 volume={39},
 year={1952}
}

@article{thurstone,
	title={A law of comparative judgment.},
	volume={34},
	issn={1939-1471(Electronic),0033-295X(Print)},
	doi={10.1037/h0070288},
	abstract={A new psychological law, called the law of comparative judgment, is presented with some of its special applications in the measurement of psychological values. This law is applicable not only to the comparison of physical stimulus intensities but also to qualitative comparative judgments, such as those of excellence of specimens in an educational scale. It should be possible also to verify it on comparative judgments which involve simultaneous and successive contrast. The law is stated as follows:[Equation omitted]in which S1 and S2 are the psychological scale values of the two compared stimuli; x12 is the sigma value corresponding to the proportion of judgments p1 {\textgreater} p2. ς1 is the discriminal dispersion of stimulus R1 and ς2 is the dispersion of stimulus R2. r is the correlation between the discriminal deviations of R1 and R2 in the same judgment. This law is basic for work on Weber's and Fechner's laws, applies to the judgments of a single observer who compares a series of stimuli by the method of paired comparisons when no "equal" judgments are allowed, and is a rational equation for the method of constant stimuli. The law is then applied to five cases each of which involves different assumptions and different degrees of simplification of the law for practical use. The weighting of the observation equations is discussed because the observation equations obtained with the five cases are not of the same reliability and hence should not be equally weighted. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number={4},
	journal={Psychological Review},
	author={Thurstone, L. L.},
	year={1927},
	note={Place: US
Publisher: Psychological Review Company},
	keywords={*Judgment, Values},
	pages={273--286},
}

@misc{2001.04465,
    Author={Andreea Bobu and Dexter R. R. Scobee and Jaime F. Fisac and S. Shankar Sastry and Anca D. Dragan},
    Title={LESS is More: Rethinking Probabilistic Models of Human Behavior},
    Year={2020},
    Eprint={arXiv:2001.04465},
    Doi={10.1145/3319502.3374811},
}

@misc{2307.09288,
Author={Hugo Touvron and others},
Title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
Year={2023},
Eprint={2307.09288},
Eprinttype={arXiv},
}

@article{Luce1977,
  doi={10.1016/0022-2496(77)90032-3},
  url={https://doi.org/10.1016/0022-2496(77)90032-3},
  year={1977},
  month=jun,
  publisher={Elsevier {BV}},
  volume={15},
  number={3},
  pages={215--233},
  author={R.Duncan Luce},
  title={The choice axiom after twenty years},
  journal={Journal of Mathematical Psychology}
}

@book{VonNeumannMorgenstern1945,
  author   ={John Von Neumann and Oskar Morgenstern},
  title    ={Theory of Games and Economic Behavior},
  publisher={Princeton University Press},
  address  ={Princeton, NJ},
  year     ={1945}
}

@misc{Liang2021,
Author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
Title={On the Opportunities and Risks of Foundation Models},
Year={2021},
Eprint={arXiv:2108.07258},
}

@inproceedings{NEURIPS2019_1fd09c5f,
 author={Hiranandani, Gaurush and Boodaghians, Shant and Mehta, Ruta and Koyejo, Oluwasanmi O},
 booktitle={Advances in Neural Information Processing Systems},
 editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages={},
 publisher={Curran Associates, Inc.},
 title={Multiclass Performance Metric Elicitation},
 url={https://proceedings.neurips.cc/paper_files/paper/2019/file/1fd09c5f59a8ff35d499c0ee25a1d47e-Paper.pdf},
 volume={32},
 year={2019}
}


@InProceedings{pmlr-v89-hiranandani19a,
  title=	 {Performance Metric Elicitation from Pairwise Classifier Comparisons},
  author=      {Hiranandani, Gaurush and Boodaghians, Shant and Mehta, Ruta and Koyejo, Oluwasanmi},
  booktitle=	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages=	 {371--379},
  year=	 {2019},
  editor=	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume=	 {89},
  series=	 {Proceedings of Machine Learning Research},
  month=	 {16--18 Apr},
  publisher=   {PMLR},
  pdf=	 {http://proceedings.mlr.press/v89/hiranandani19a/hiranandani19a.pdf},
  url=	 {https://proceedings.mlr.press/v89/hiranandani19a.html},
  abstract=	 {Given a binary prediction problem, which performance metric should the classifier optimize? We address this question by formalizing the problem of Metric Elicitation. The goal of metric elicitation is to discover the performance metric of a practitioner, which reflects her innate rewards (costs) for correct (incorrect) classification. In particular, we focus on eliciting binary classification performance metrics from pairwise feedback, where a practitioner is queried to provide relative preference between two classifiers. By exploiting key geometric properties of the space of confusion matrices, we obtain provably query efficient algorithms for eliciting linear and linear-fractional performance metrics. We further show that our method is robust to feedback and finite sample noise.}
}


@article{YangNaiman+2014+477+496,
url={https://doi.org/10.1515/sagmb-2013-0053},
title={Multiclass cancer classification based  on gene expression comparison},
author={Sitan Yang and Daniel Q. Naiman},
pages={477--496},
volume={13},
number={4},
journal={Statistical Applications in Genetics and Molecular Biology},
doi={doi:10.1515/sagmb-2013-0053},
year={2014},
lastchecked={2023-10-29}
}



@InProceedings{pmlr-v37-narasimhanb15,
  title=	 {Consistent Multiclass Algorithms for Complex Performance Measures},
  author=	 {Narasimhan, Harikrishna and Ramaswamy, Harish and Saha, Aadirupa and Agarwal, Shivani},
  booktitle=	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages=	 {2398--2407},
  year=	 {2015},
  editor=	 {Bach, Francis and Blei, David},
  volume=	 {37},
  series=	 {Proceedings of Machine Learning Research},
  address=	 {Lille, France},
  month=	 {07--09 Jul},
  publisher=   {PMLR},
  pdf=	 {http://proceedings.mlr.press/v37/narasimhanb15.pdf},
  url=	 {https://proceedings.mlr.press/v37/narasimhanb15.html},
  abstract=	 {This paper presents new consistent algorithms for multiclass learning with complex performance measures, defined by arbitrary functions of the confusion matrix. This setting includes as a special case all loss-based performance measures, which are simply linear functions of the confusion matrix, but also includes more complex performance measures such as the multiclass G-mean and micro F_1 measures. We give a general framework for designing consistent algorithms for such performance measures by viewing the learning problem as an optimization problem over the set of feasible confusion matrices, and give two specific instantiations based on the Frank-Wolfe method for concave performance measures and on the bisection method for ratio-of-linear performance measures. The resulting algorithms are provably consistent and outperform a multiclass version of the state-of-the-art SVMperf method in experiments; for large multiclass problems, the algorithms are also orders of magnitude faster than SVMperf.}
}

@inproceedings{NIPS2012_e6d8545d,
 author={Jamieson, Kevin G and Nowak, Robert and Recht, Ben},
 booktitle={Advances in Neural Information Processing Systems},
 editor={F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages={},
 publisher={Curran Associates, Inc.},
 title={Query Complexity of Derivative-Free Optimization},
 url={https://proceedings.neurips.cc/paper_files/paper/2012/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf},
 volume={25},
 year={2012}
}

@inproceedings{ab,
    author={Tamburrelli, Giordano and Margara, Alessandro},
    year={2014},
    month={08},
    pages={},
    title={Towards Automated A/B Testing},
    isbn={978-3-319-09939-2},
    doi={10.1007/978-3-319-09940-8_13},
    booktitle={Search-Based Software Engineering}
}


@article{pref1,
 ISSN={00130427, 14680335},
 URL={http://www.jstor.org/stable/2548836},
 author={P. A. Samuelson},
 journal={Economica},
 number={17},
 pages={61--71},
 publisher={[London School of Economics, Wiley, London School of Economics and Political Science, Suntory and Toyota International Centres for Economics and Related Disciplines]},
 title={A Note on the Pure Theory of Consumer's Behaviour},
 urldate={2023-11-13},
 volume={5},
 year={1938}
}

@article{pref2,
 ISSN={00129682, 14680262},
 URL={http://www.jstor.org/stable/1912308},
 author={Andreu Mas-Colell},
 journal={Econometrica},
 number={6},
 pages={1409--1430},
 publisher={[Wiley, Econometric Society]},
 title={The Recoverability of Consumers' Preferences from Market Demand Behavior},
 urldate={2023-11-13},
 volume={45},
 year={1977}
}
@inproceedings{pref3,
  title={Revealed Preference},
  author={Hal R. Varian},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:1632873},
  booktitle={The SAGE Encyclopedia of Business Ethics and Society},
}


@misc{pref4,
      title={Minimax regret based elicitation of generalized additive utilities}, 
      author={Darius Braziunas and Craig Boutilier},
      year={2012},
      eprint={1206.5255},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@inproceedings{nips,
 author={Hiranandani, Gaurush and Narasimhan, Harikrishna and Koyejo, Sanmi},
 booktitle={Advances in Neural Information Processing Systems},
 editor={H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages={11083--11095},
 publisher={Curran Associates, Inc.},
 title={Fair Performance Metric Elicitation},
 url={https://proceedings.neurips.cc/paper_files/paper/2020/file/7ec2442aa04c157590b2fa1a7d093a33-Paper.pdf},
 volume={33},
 year={2020}
}


@inproceedings{bouneffouf2020survey,
    author={Bouneffouf, Djallel and Rish, Irina and Aggarwal, Charu},
    title={Survey on Applications of Multi-Armed and Contextual Bandits},
    year={2020},
    publisher={IEEE Press},
    url={https://doi.org/10.1109/CEC48606.2020.9185782},
    doi={10.1109/CEC48606.2020.9185782},
    abstract={In recent years, the multi-armed bandit (MAB) framework has attracted a lot of attention in various applications, from recommender systems and information retrieval to healthcare and finance. This success is due to its stellar performance combined with attractive properties, such as learning from less feedback. The multiarmed bandit field is currently experiencing a renaissance, as novel problem settings and algorithms motivated by various practical applications are being introduced, building on top of the classical bandit problem. This article aims to provide a comprehensive review of top recent developments in multiple real-life applications of the multi-armed bandit. Specifically, we introduce a taxonomy of common MAB-based applications and summarize the state-of-the-art for each of those domains. Furthermore, we identify important current trends and provide new perspectives pertaining to the future of this burgeoning field.},
    booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)},
    pages={1–8},
    numpages={8},
    location={Glasgow, United Kingdom}
}

@article{advancements_dueling, title={Advancements in dueling bandits}, DOI={10.24963/ijcai.2018/776}, journal={Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence}, author={Sui, Yanan and Zoghi, Masrour and Hofmann, Katja and Yue, Yisong}, year={2018}} 

@article{IR, title={Interactively optimizing information retrieval systems as a dueling bandits problem}, DOI={10.1145/1553374.1553527}, journal={Proceedings of the 26th Annual International Conference on Machine Learning}, author={Yue, Yisong and Joachims, Thorsten}, year={2009}} 


@InProceedings{Contextual_Dueling,
  title={Contextual Dueling Bandits},
  author={Dudík, Miroslav and Hofmann, Katja and Schapire, Robert E. and Slivkins, Aleksandrs and Zoghi, Masrour},
  booktitle={Proceedings of The 28th Conference on Learning Theory},
  pages=	{563--587},
  year={2015},
  editor={Grünwald, Peter and Hazan, Elad and Kale, Satyen},
  volume={40},
  series={Proceedings of Machine Learning Research},
  address={Paris, France},
  month={03--06 Jul},
  publisher={PMLR},
  pdf={http://proceedings.mlr.press/v40/Dudik15.pdf},
  url={https://proceedings.mlr.press/v40/Dudik15.html},
  abstract={We consider the problem of learning to choose actions using contextual information when provided with limited feedback in the form of relative pairwise comparisons. We study this problem in the dueling-bandits framework of Yue et al. (COLT’09), which we extend to incorporate context. Roughly, the learner’s goal is to find the best policy, or way of behaving, in some space of policies, although “best” is not always so clearly defined. Here, we propose a new and natural solution concept, rooted in game theory, called a \emphvon Neumann winner, a randomized policy that beats or ties every other policy. We show that this notion overcomes important limitations of existing solutions, particularly the Condorcet winner which has typically been used in the past, but which requires strong and often unrealistic assumptions. We then present three \emphefficient algorithms for online learning in our setting, and for approximating a von Neumann winner from batch-like data. The first of these algorithms achieves particularly low regret, even when data is adversarial, although its time and space requirements are linear in the size of the policy space. The other two algorithms require time and space only logarithmic in the size of the policy space when provided access to an oracle for solving classification problems on the space.}
}

@article{huo2017risk,
    author={Huo, Xiaoguang and Fu, Feng},
    year={2017},
    month={11},
    pages={},
    title={Risk-Aware Multi-Armed Bandit Problem with Application to Portfolio Selection},
    volume={4},
    journal={Royal Society Open Science},
    doi={10.1098/rsos.171377}
}

@inproceedings{shen2015portfolio,
    author={Shen, Weiwei and Wang, Jun and Jiang, Yu-Gang and Zha, Hongyuan},
    title={Portfolio Choices with Orthogonal Bandit Learning},
    year={2015},
    isbn={9781577357384},
    publisher={AAAI Press},
    abstract={The investigation and development of new methods from diverse perspectives to shed light on portfolio choice problems has never stagnated in financial research. Recently, multi-armed bandits have drawn intensive attention in various machine learning applications in online settings. The tradeoff between exploration and exploitation to maximize rewards in bandit algorithms naturally establishes a connection to portfolio choice problems. In this paper, we present a bandit algorithm for conducting online portfolio choices by effectually exploiting correlations among multiple arms. Through constructing orthogonal portfolios from multiple assets and integrating with the upper confidence bound bandit framework, we derive the optimal portfolio strategy that represents the combination of passive and active investments according to a risk-adjusted reward function. Compared with oft-quoted trading strategies in finance and machine learning fields across representative real-world market datasets, the proposed algorithm demonstrates superiority in both risk-adjusted return and cumulative wealth.},
    booktitle={Proceedings of the 24th International Conference on Artificial Intelligence},
    pages={974–980},
    numpages={7},
    location={Buenos Aires, Argentina},
    series={IJCAI'15}
}

@article{bastani2020online,
    author={Bastani, Hamsa and Bayati, Mohsen},
    title={Online Decision Making with High-Dimensional Covariates},
    journal={Operations Research},
    volume={68},
    number={1},
    pages={276-294},
    year={2020},
    doi={10.1287/opre.2019.1902},
}

@InProceedings{bouneffouf2017bandit,
    author="Bouneffouf, Djallel
    and Rish, Irina
    and Cecchi, Guillermo A.",
    editor="Everitt, Tom
    and Goertzel, Ben
    and Potapov, Alexey",
    title="Bandit Models of Human Behavior: Reward Processing in Mental Disorders",
    booktitle="Artificial General Intelligence",
    year="2017",
    publisher="Springer International Publishing",
    address="Cham",
    pages="237--248",
    abstract="Drawing an inspiration from behavioral studies of human decision making, we propose here a general parametric framework for multi-armed bandit problem, which extends the standard Thompson Sampling approach to incorporate reward processing biases associated with several neurological and psychiatric conditions, including Parkinson's and Alzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD), addiction, and chronic pain. We demonstrate empirically that the proposed parametric approach can often outperform the baseline Thompson Sampling on a variety of datasets. Moreover, from the behavioral modeling perspective, our parametric framework can be viewed as a first step towards a unifying computational model capturing reward processing abnormalities across multiple mental conditions.",
    isbn="978-3-319-63703-7"
}

@article{misra2019dynamic,
    author={Misra, Kanishka and Schwartz, Eric M. and Abernethy, Jacob},
    title={Dynamic Online Pricing with Incomplete Information Using Multiarmed Bandit Experiments},
    journal={Marketing Science},
    volume={38},
    number={2},
    pages={226-252},
    year={2019},
    doi={10.1287/mksc.2018.1129},
}

@InProceedings{zhou2017large,
author="Zhou, Qian
and Zhang, XiaoFang
and Xu, Jin
and Liang, Bin",
editor="Liu, Derong
and Xie, Shengli
and Li, Yuanqing
and Zhao, Dongbin
and El-Alfy, El-Sayed M.",
title="Large-Scale Bandit Approaches for Recommender Systems",
booktitle="Neural Information Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="811--821",
abstract="Recommender systems have been successfully applied to many application areas to predict users' preference. However, these systems face the exploration-exploitation dilemma when making a recommendation, since they need to exploit items which raise users' interest and explore new items to improve satisfaction simultaneously. In this paper, we deal with this dilemma through Multi-Armed Bandit (MAB) approaches, especially for large-scale recommender systems that have vast or infinite items. We propose two large-scale bandit approaches under the situations that there is no available priori information. The continuous exploration in our approaches can address the cold start problem in recommender systems. Furthermore, our context-free approaches are based on users' click behavior without the dependence on priori information. We theoretically prove that our approaches can converge to optimal item recommendations in the long run. Experimental results indicate that our approaches are able to provide more accurate recommendations than some classic bandit approaches in terms of click-through rates, with less calculation time.",
isbn="978-3-319-70087-8"
}

@InProceedings{bouneffouf2012a,
    author="Bouneffouf, Djallel
    and Bouzeghoub, Amel
    and Gan{\c{c}}arski, Alda Lopes",
    editor="Huang, Tingwen
    and Zeng, Zhigang
    and Li, Chuandong
    and Leung, Chi Sing",
    title="A Contextual-Bandit Algorithm for Mobile Context-Aware Recommender System",
    booktitle="Neural Information Processing",
    year="2012",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="324--331",
    abstract="Most existing approaches in Mobile Context-Aware Recommender Systems focus on recommending relevant items to users taking into account contextual information, such as time, location, or social aspects. However, none of them has considered the problem of user's content evolution. We introduce in this paper an algorithm that tackles this dynamicity. It is based on dynamic exploration/exploitation and can adaptively balance the two aspects by deciding which user's situation is most relevant for exploration or exploitation. Within a deliberately designed offline simulation framework we conduct evaluations with real online event log data. The experimental results demonstrate that our algorithm outperforms surveyed algorithms.",
    isbn="978-3-642-34487-9"
}

@inproceedings{liu2018customized,
    author={Liu, Bing and Yu, Tong and Lane, Ian and Mengshoel, Ole J.},
    title={Customized Nonlinear Bandits for Online Response Selection in Neural Conversation Models},
    year={2018},
    isbn={978-1-57735-800-8},
    publisher={AAAI Press},
    booktitle={Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
    articleno={643},
    numpages={8},
    location={New Orleans, Louisiana, USA},
    series={AAAI'18/IAAI'18/EAAI'18}
}

@misc{
    perez2018contextual,
    title={Contextual memory bandit for pro-active dialog engagement},
    author={julien perez and Tomi Silander},
    year={2018},
    url={https://openreview.net/forum?id=SJiHOSeR-},
}

@misc{upadhyay2019a,
    author={Upadhyay, Sohini and Agarwal, Mayank and Bouneffouf, Djallel and Khazaeni, Yasaman},
    year={2019},
    month={06},
    pages={},
    title={A Bandit Approach to Posterior Dialog Orchestration Under a Budget}
}

@inproceedings{ding2019interactive,
    author={Ding, Kaize and Li, Jundong and Liu, Huan},
    title={Interactive Anomaly Detection on Attributed Networks},
    year={2019},
    isbn={9781450359405},
    publisher={Association for Computing Machinery},
    address={New York, NY, USA},
    url={https://doi.org/10.1145/3289600.3290964},
    doi={10.1145/3289600.3290964},
    booktitle={Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
    pages={357–365},
    numpages={9},
    keywords={multi-armed bandit, attributed networks, anomaly detection},
    location={Melbourne VIC, Australia},
    series={WSDM '19}
}


@article{YUE20121538,
	abstract={We study a partial-information online-learning problem where actions are restricted to noisy comparisons between pairs of strategies (also known as bandits). In contrast to conventional approaches that require the absolute reward of the chosen strategy to be quantifiable and observable, our setting assumes only that (noisy) binary feedback about the relative reward of two chosen strategies is available. This type of relative feedback is particularly appropriate in applications where absolute rewards have no natural scale or are difficult to measure (e.g., user-perceived quality of a set of retrieval results, taste of food, product attractiveness), but where pairwise comparisons are easy to make. We propose a novel regret formulation in this setting, as well as present an algorithm that achieves information-theoretically optimal regret bounds (up to a constant factor).},
	author={Yisong Yue and Josef Broder and Robert Kleinberg and Thorsten Joachims},
	doi={https://doi.org/10.1016/j.jcss.2011.12.028},
	issn={0022-0000},
	journal={Journal of Computer and System Sciences},
	keywords={Online learning, Multi-armed bandits, Preference elicitation},
	note={JCSS Special Issue: Cloud Computing 2011},
	number={5},
	pages={1538-1556},
	title={The K-armed dueling bandits problem},
	url={https://www.sciencedirect.com/science/article/pii/S0022000012000281},
	volume={78},
	year={2012},
	bdsk-url-1={https://www.sciencedirect.com/science/article/pii/S0022000012000281},
	bdsk-url-2={https://doi.org/10.1016/j.jcss.2011.12.028}}


@misc{tucker2020preferencebased,
      title={Preference-Based Learning for Exoskeleton Gait Optimization}, 
      author={Maegan Tucker and Ellen Novoseller and Claudia Kann and Yanan Sui and Yisong Yue and Joel Burdick and Aaron D. Ames},
      year={2020},
      eprint={1909.12316},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{hejna2023few,
  title={Few-shot preference learning for human-in-the-loop rl},
  author={Hejna III, Donald Joseph and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={2014--2025},
  year={2023},
  organization={PMLR}
}

@inproceedings{zhou2019watch,
  title={Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards},
  author={Zhou, Allan and Jang, Eric and Kappler, Daniel and Herzog, Alex and Khansari, Mohi and Wohlhart, Paul and Bai, Yunfei and Kalakrishnan, Mrinal and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{lee2021pebble,
  title={Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training},
  author={Lee, Kimin and Smith, Laura and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2106.05091},
  year={2021}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{myers2022learning,
  title={Learning multimodal rewards from rankings},
  author={Myers, Vivek and Biyik, Erdem and Anari, Nima and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={342--352},
  year={2022},
  organization={PMLR}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{padalkar2023open,
  title={Open X-Embodiment: Robotic learning datasets and RT-X models},
  author={Padalkar, Abhishek and Pooley, Acorn and Jain, Ajinkya and Bewley, Alex and Herzog, Alex and Irpan, Alex and Khazatsky, Alexander and Rai, Anant and Singh, Anikait and Brohan, Anthony and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{rogers1999adaptive,
  title={An adaptive interactive agent for route advice},
  author={Rogers, Seth and Fiechter, Claude-Nicolas and Langley, Pat},
  booktitle={Proceedings of the third annual conference on Autonomous Agents},
  pages={198--205},
  year={1999}
}

@article{thompson2004personalized,
  title={A personalized system for conversational recommendations},
  author={Thompson, Cynthia A and Goker, Mehmet H and Langley, Pat},
  journal={Journal of Artificial Intelligence Research},
  volume={21},
  pages={393--428},
  year={2004}
}

@inproceedings{langley1999adaptive,
  title={An adaptive conversational interface for destination advice},
  author={Langley, Pat and Thompson, Cynthia and Elio, Renee and Haddadi, Afsaneh},
  booktitle={International Workshop on Cooperative Information Agents},
  pages={347--364},
  year={1999},
  organization={Springer}
}

@inproceedings{gervasio1999learning,
  title={Learning user evaluation functions for adaptive scheduling assistance},
  author={Gervasio, Melinda T and Iba, Wayne and Langley, Pat},
  booktitle={ICML},
  pages={152--161},
  year={1999},
  organization={Citeseer}
}



@book{cheney_baboon_2008,
	title={Baboon metaphysics: {The} evolution of a social mind},
	isbn={0-226-10244-0},
	publisher={University of Chicago Press},
	author={Cheney, Dorothy L. and Seyfarth, Robert M.},
	year={2008},
	note={https://ebookcentral-proquest-com.offcampus.lib.washington.edu/lib/washington/detail.action?docID=584929},
	file={chapter_eight.pdf:/Users/jared/Zotero/storage/4EICM69F/chapter_eight.pdf:application/pdf;chapter_six.pdf:/Users/jared/Zotero/storage/2DFSDH39/chapter_six.pdf:application/pdf},
}

@misc{2310.13639,
Author={Joey Hejna and Rafael Rafailov and Harshit Sikchi and Chelsea Finn and Scott Niekum and W. Bradley Knox and Dorsa Sadigh},
Title={Contrastive Preference Learning: Learning from Human Feedback without RL},
Year={2023},
Eprint={arXiv:2310.13639},
}
@book{quine_word_1960,
	title={Word and object},
	isbn={0-262-31280-8},
	url={https://openlibrary.org/works/OL2910272W?edition=ia%3Awordobject00quin},
	publisher={MIT Press},
	author={Quine, Willard Van Orman},
	year={1960},
}

@book{tomasello_becoming_2019,
	address={Cambridge, MA},
	title={Becoming human: {A} theory of ontogeny},
	isbn={0-674-98085-9},
	publisher={Belknap Press},
	author={Tomasello, Michael},
	year={2019},
}

@article{talat_word_nodate,
  title={A word on machine ethics: A response to Jiang et al.(2021)},
  author={Talat, Zeerak and Blix, Hagen and Valvoda, Josef and Ganesh, Maya Indira and Cotterell, Ryan and Williams, Adina},
  journal={arXiv preprint arXiv:2111.04158},
  year={2021}
}

@article{jiang_delphi_2021,
	title={Delphi: {Towards} {Machine} {Ethics} and {Norms}},
	shorttitle={Delphi},
	url={http://arxiv.org/abs/2110.07574},
	abstract={What would it take to teach a machine to behave ethically? While broad ethical rules may seem straightforward to state ("thou shalt not kill"), applying such rules to real-world situations is far more complex. For example, while "helping a friend" is generally a good thing to do, "helping a friend spread fake news" is not. We identify four underlying challenges towards machine ethics and norms: (1) an understanding of moral precepts and social norms; (2) the ability to perceive real-world situations visually or by reading natural language descriptions; (3) commonsense reasoning to anticipate the outcome of alternative actions in different contexts; (4) most importantly, the ability to make ethical judgments given the interplay between competing values and their grounding in different contexts (e.g., the right to freedom of expression vs. preventing the spread of fake news). Our paper begins to address these questions within the deep learning paradigm. Our prototype model, Delphi, demonstrates strong promise of language-based commonsense moral reasoning, with up to 92.1\% accuracy vetted by humans. This is in stark contrast to the zero-shot performance of GPT-3 of 52.3\%, which suggests that massive scale alone does not endow pre-trained neural language models with human values. Thus, we present Commonsense Norm Bank, a moral textbook customized for machines, which compiles 1.7M examples of people's ethical judgments on a broad spectrum of everyday situations. In addition to the new resources and baseline performances for future research, our study provides new insights that lead to several important open research questions: differentiating between universal human values and personal values, modeling different moral frameworks, and explainable, consistent approaches to machine ethics.},
	language={en},
	urldate={2021-12-31},
	journal={arXiv:2110.07574 [cs]},
	author={Jiang, Liwei and Hwang, Jena D. and Bhagavatula, Chandra and Bras, Ronan Le and Forbes, Maxwell and Borchardt, Jon and Liang, Jenny and Etzioni, Oren and Sap, Maarten and Choi, Yejin},
	month=oct,
	year={2021},
	note={arXiv: 2110.07574},
	keywords={Computer Science - Computation and Language},
	file={Jiang et al. - 2021 - Delphi Towards Machine Ethics and Norms.pdf:/Users/jared/Zotero/storage/WH4FNGEF/Jiang et al. - 2021 - Delphi Towards Machine Ethics and Norms.pdf:application/pdf},
}

@article{sap_socialiqa_2019,
	title={{SocialIQA}: {Commonsense} {Reasoning} about {Social} {Interactions}},
	shorttitle={{SocialIQA}},
	url={http://arxiv.org/abs/1904.09728},
	abstract={We introduce SOCIAL IQA, the ﬁrst largescale benchmark for commonsense reasoning about social situations. SOCIAL IQA contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: “Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?” A: “Make sure no one else could hear”). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance ({\textgreater}20\% gap). Notably, we further establish SOCIAL IQA as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).},
	language={en},
	urldate={2022-02-24},
	journal={arXiv:1904.09728 [cs]},
	author={Sap, Maarten and Rashkin, Hannah and Chen, Derek and LeBras, Ronan and Choi, Yejin},
	month=sep,
	year={2019},
	note={arXiv: 1904.09728},
	keywords={Computer Science - Computation and Language},
	file={Sap et al. - 2019 - SocialIQA Commonsense Reasoning about Social Inte.pdf:/Users/jared/Zotero/storage/YLEKK6A6/Sap et al. - 2019 - SocialIQA Commonsense Reasoning about Social Inte.pdf:application/pdf},
}

@phdthesis{ziebart_modeling_2010,
	title={Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy},
	abstract={This thesis introduces the principle of maximum causal entropy as a framework for modeling purposeful adaptive behavior in uncertain environments. It provides a novel perspective on behavior modeling, emphasizing the role of uncertainty and the agent's own influence on its environment. The principle of maximum causal entropy is applied to various scenarios, demonstrating its effectiveness in capturing the complexities of decision-making processes. This work contributes to the field of machine learning by offering a robust and flexible approach for understanding and predicting agent behavior, with potential applications in areas such as robotics and human-computer interaction.},
	author={Ziebart, Brian D.},
	year={2010},
	school={Carnegie Mellon University},
	address={Pittsburgh, PA},
	committee={J. Andrew Bagnell, Co-chair and Anind K. Dey, Co-chair and Martial Hebert and Dieter Fox, University of Washington},
	note={Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy},
	type={PhD Thesis},
	id={CMU-ML-10-110},
	file={Ziebart - 2010 - Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy.pdf:/Path/Ziebart - 2010 - Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy.pdf:application/pdf},
}


@article{hejna_contrastive_2023,
  title={Contrastive prefence learning: Learning from human feedback without rl},
  author={Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W Bradley and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2310.13639},
  year={2023}
}

@misc{vanhasselt_deep_2018,
	title={Deep Reinforcement Learning and the Deadly Triad},
	abstract={This paper addresses the 'deadly triad' in the context of deep reinforcement learning, a phenomenon where the combination of function approximation, bootstrapping, and off-policy learning can lead to instability and divergence in learning. The authors provide an in-depth analysis of the interactions within the triad and propose strategies to mitigate its negative effects. The study contributes to a better understanding of the challenges and potential pitfalls in the design of deep reinforcement learning algorithms, and offers insights into developing more stable and robust solutions in complex learning environments.},
	author={van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
	year={2018},
	eprint={arXiv:1812.02648},
	pages={Number of pages},
	file={van Hasselt et al. - 2018 - Deep Reinforcement Learning and the Deadly Triad.pdf:/Path/van Hasselt et al. - 2018 - Deep Reinforcement Learning and the Deadly Triad.pdf:application/pdf},
}

@misc{ouyang_training_2022,
	title={Training Language Models to Follow Instructions with Human Feedback},
	abstract={This research introduces a groundbreaking approach for training language models to adhere to instructions more effectively by incorporating human feedback. The study demonstrates the potential of using human judgments to refine and guide the training process of language models, aiming to enhance their ability to understand and execute complex instructions. This method represents an innovative direction in language model training, emphasizing a synergistic interaction between human insights and machine learning algorithms. The results show significant improvements in the model's performance in following instructions accurately, marking a step forward in creating more intuitive and responsive AI systems.},
	author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	year={2022},
	eprint={arXiv:2203.02155},
	pages={Number of pages},
	file={Ouyang et al. - 2022 - Training Language Models to Follow Instructions with Human Feedback.pdf:/Path/Ouyang et al. - 2022 - Training Language Models to Follow Instructions with Human Feedback.pdf:application/pdf},
}

@misc{stiennon_learning_2020,
	title={Learning to Summarize from Human Feedback},
	abstract={This paper presents a novel approach to training language models for the task of summarization using human feedback. The study explores the effectiveness of incorporating direct human inputs as part of the training process, aiming to align the model's output more closely with human expectations and preferences. This methodology signifies a shift from conventional training paradigms towards a more interactive and human-centric approach. The findings suggest that models trained with human feedback not only perform better in generating summaries that are coherent and contextually relevant but also show an increased alignment with nuanced human judgment, paving the way for more sophisticated language processing applications.},
	author={Stiennon, Nisan and Ouyang, Long and Wu, Jeff and Ziegler, Daniel M. and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul},
	year={2020},
	eprint={arXiv:2009.01325},
	pages={Number of pages},
	file={Stiennon et al. - 2020 - Learning to Summarize from Human Feedback.pdf:/Path/Stiennon et al. - 2020 - Learning to Summarize from Human Feedback.pdf:application/pdf},
}

@article{hendrycks_aligning_2021,
  title={Aligning ai with shared human values},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2008.02275},
  year={2020}
}

@article{hendrycks_what_2021,
	title={What {Would} {Jiminy} {Cricket} {Do}? {Towards} {Agents} {That} {Behave} {Morally}},
	shorttitle={What {Would} {Jiminy} {Cricket} {Do}?},
	url={http://arxiv.org/abs/2110.13136},
	abstract={When making everyday decisions, people are guided by their conscience, an internal sense of right and wrong. By contrast, artiﬁcial agents are not currently endowed with a moral sense. As a consequence, they may unknowingly act immorally, especially when trained on environments that disregard moral concerns such as violent video games. With the advent of generally capable agents that pretrain on many environments, it will become necessary to mitigate inherited biases from such environments that teach immoral behavior. To facilitate the development of agents that avoid causing wanton harm, we introduce Jiminy Cricket, an environment suite of 25 text-based adventure games with thousands of diverse, morally salient scenarios. By annotating every possible game state, the Jiminy Cricket environments robustly evaluate whether agents can act morally while maximizing reward. Using models with commonsense moral knowledge, we create an elementary artiﬁcial conscience that assesses and guides agents. In extensive experiments, we ﬁnd that the artiﬁcial conscience approach can steer agents towards moral behavior without sacriﬁcing performance.},
	language={en},
	urldate={2022-02-26},
	journal={arXiv:2110.13136 [cs]},
	author={Hendrycks, Dan and Mazeika, Mantas and Zou, Andy and Patel, Sahil and Zhu, Christine and Navarro, Jesus and Song, Dawn and Li, Bo and Steinhardt, Jacob},
	year={2021},
	note={arXiv: 2110.13136},
	keywords={Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file={Hendrycks et al. - 2022 - What Would Jiminy Cricket Do Towards Agents That .pdf:/Users/jared/Zotero/storage/ASJ83LDA/Hendrycks et al. - 2022 - What Would Jiminy Cricket Do Towards Agents That .pdf:application/pdf},
}

@misc{arcas_can_2022,
	title={Can machines learn how to behave?},
	url={https://medium.com/@blaisea/can-machines-learn-how-to-behave-42a02a57fadb},
	abstract={Beyond the current news cycle about whether AIs are sentient is a more practical and immediately consequential conversation about AI value…},
	language={en},
	urldate={2022-08-03},
	journal={Medium},
	author={Arcas, Blaise Aguera y},
	month=aug,
	year={2022},
	file={Snapshot:/Users/jared/Zotero/storage/5ERWKNYJ/can-machines-learn-how-to-behave-42a02a57fadb.html:text/html},
}

@book{churchland_conscience_2019,
	address={New York},
	edition={First edition},
	title={Conscience: the origins of moral intuition},
	isbn={978-1-324-00089-1},
	shorttitle={Conscience},
	publisher={W. W. Norton \& Company},
	author={Churchland, Patricia Smith},
	year={2019},
	keywords={Conscience},
	file={chapter_1.pdf:/Users/jared/Zotero/storage/7XVYKFCW/chapter_1.pdf:application/pdf;chapter_2_beginning.pdf:/Users/jared/Zotero/storage/JX2D2AUD/chapter_2_beginning.pdf:application/pdf;chapter_7.pdf:/Users/jared/Zotero/storage/K7W2WUNU/chapter_7.pdf:application/pdf},
}

@techreport{weidinger_artificial_2022,
	type={preprint},
	title={Artificial moral cognition: {Learning} from developmental psychology},
	shorttitle={Artificial moral cognition},
	url={https://osf.io/tnf4e},
	abstract={An artificial system that successfully performs cognitive tasks may pass tests of 'intelligence' but not yet operate in ways that are morally appropriate. An important step towards  developing moral artificial intelligence (AI) is to build robust methods for assessing moral capacities in these systems. Here, we present a framework for analysing and evaluating moral capacities in AI systems, which decomposes moral capacities into tractable analytical targets and produces tools for measuring artificial moral cognition. We show that decomposing moral cognition in this way can shed light on the presence, scaffolding, and interdependencies of amoral and moral capacities in AI systems. Our analysis framework produces a virtuous circle, whereby developmental psychology can enhance how AI systems are built, evaluated, and iterated on as moral agents; and analysis of moral capacities in AI can generate new hypotheses surrounding mechanisms within the human moral mind.},
	language={en},
	urldate={2022-08-20},
	institution={PsyArXiv},
	author={Weidinger, Laura and Reinecke, Madeline G. and Haas, Julia},
	month=aug,
	year={2022},
	doi={10.31234/osf.io/tnf4e},
	file={Weidinger et al. - 2022 - Artificial moral cognition Learning from developm.pdf:/Users/jared/Zotero/storage/G4UZW2JY/Weidinger et al. - 2022 - Artificial moral cognition Learning from developm.pdf:application/pdf},
}

@article{mazeika_how_2022,
	title={How {Would} {The} {Viewer} {Feel}? {Estimating} {Wellbeing} {From} {Video} {Scenarios}},
	shorttitle={How {Would} {The} {Viewer} {Feel}?},
	journal={arXiv preprint arXiv:2210.10039},
	author={Mazeika, Mantas and Tang, Eric and Zou, Andy and Basart, Steven and Chan, Jun Shern and Song, Dawn and Forsyth, David and Steinhardt, Jacob and Hendrycks, Dan},
	year={2022},
}

@book{gert_common_2004,
	title={Common morality: {Deciding} what to do},
	isbn={0-19-988394-7},
	publisher={Oxford University Press},
	author={Gert, Bernard},
	year={2004},
}

@book{kagan_normative_1998,
	address={Boulder, Colo},
	series={Dimensions of philosophy series},
	title={Normative ethics},
	isbn={978-0-8133-0845-6 978-0-8133-0846-3},
	publisher={Westview Press},
	author={Kagan, Shelly},
	year={1998},
	keywords={Ethics},
}

@article{vamplew_human-aligned_2018,
	title={Human-aligned artificial intelligence is a multiobjective problem},
	volume={20},
	issn={1572-8439},
	url={https://doi.org/10.1007/s10676-017-9440-6},
	doi={10.1007/s10676-017-9440-6},
	abstract={As the capabilities of artificial intelligence (AI) systems improve, it becomes important to constrain their actions to ensure their behaviour remains beneficial to humanity. A variety of ethical, legal and safety-based frameworks have been proposed as a basis for designing these constraints. Despite their variations, these frameworks share the common characteristic that decision-making must consider multiple potentially conflicting factors. We demonstrate that these alignment frameworks can be represented as utility functions, but that the widely used Maximum Expected Utility (MEU) paradigm provides insufficient support for such multiobjective decision-making. We show that a Multiobjective Maximum Expected Utility paradigm based on the combination of vector utilities and non-linear action–selection can overcome many of the issues which limit MEU’s effectiveness in implementing aligned AI. We examine existing approaches to multiobjective AI, and identify how these can contribute to the development of human-aligned intelligent agents.},
	language={en},
	number={1},
	urldate={2023-03-12},
	journal={Ethics and Information Technology},
	author={Vamplew, Peter and Dazeley, Richard and Foale, Cameron and Firmin, Sally and Mummery, Jane},
	month=mar,
	year={2018},
	keywords={Aligned artificial intelligence, Ethics, Maximum Expected Utility, Reward engineering, Value alignment},
	pages={27--40},
	file={Full Text PDF:/Users/jared/Zotero/storage/BQEMAK86/Vamplew et al. - 2018 - Human-aligned artificial intelligence is a multiob.pdf:application/pdf},
}

@article{vamplew_scalar_2022,
	title={Scalar reward is not enough: a response to {Silver}, {Singh}, {Precup} and {Sutton} (2021)},
	volume={36},
	issn={1387-2532, 1573-7454},
	shorttitle={Scalar reward is not enough},
	url={https://link.springer.com/10.1007/s10458-022-09575-5},
	doi={10.1007/s10458-022-09575-5},
	abstract={Abstract
            The recent paper “Reward is Enough” by Silver, Singh, Precup and Sutton posits that the concept of reward maximisation is sufficient to underpin all intelligence, both natural and artificial, and provides a suitable basis for the creation of artificial general intelligence. We contest the underlying assumption of Silver et al. that such reward can be scalar-valued. In this paper we explain why scalar rewards are insufficient to account for some aspects of both biological and computational intelligence, and argue in favour of explicitly multi-objective models of reward maximisation. Furthermore, we contend that even if scalar reward functions can trigger intelligent behaviour in specific cases, this type of reward is insufficient for the development of human-aligned artificial general intelligence due to unacceptable risks of unsafe or unethical behaviour.},
	language={en},
	number={2},
	urldate={2023-03-12},
	journal={Autonomous Agents and Multi-Agent Systems},
	author={Vamplew, Peter and Smith, Benjamin J. and Källström, Johan and Ramos, Gabriel and Rădulescu, Roxana and Roijers, Diederik M. and Hayes, Conor F. and Heintz, Fredrik and Mannion, Patrick and Libin, Pieter J. K. and Dazeley, Richard and Foale, Cameron},
	month=oct,
	year={2022},
	pages={41},
	file={Full Text:/Users/jared/Zotero/storage/YNR6CTNG/Vamplew et al. - 2022 - Scalar reward is not enough a response to Silver,.pdf:application/pdf},
}

@misc{gandhi_understanding_2023,
	title={Understanding {Social} {Reasoning} in {Language} {Models} with {Language} {Models}},
	url={http://arxiv.org/abs/2306.15448},
	doi={10.48550/arXiv.2306.15448},
	abstract={As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evaluations and comparable to expert-written evaluations. Using BigToM, we evaluate the social reasoning capabilities of a variety of LLMs and compare model performances with human performance. Our results suggest that GPT4 has ToM capabilities that mirror human inference patterns, though less reliable, while other LLMs struggle.},
	urldate={2023-10-02},
	publisher={arXiv},
	author={Gandhi, Kanishk and Fränken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah D.},
	month=jun,
	year={2023},
	note={arXiv:2306.15448 [cs]},
	keywords={Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file={arXiv Fulltext PDF:/Users/jared/Zotero/storage/5EJFPUIM/Gandhi et al. - 2023 - Understanding Social Reasoning in Language Models .pdf:application/pdf;arXiv.org Snapshot:/Users/jared/Zotero/storage/GDXUD4TD/2306.html:text/html},
}

@inproceedings{talat_machine_2022,
	title={On the machine learning of ethical judgments from natural language},
	booktitle={Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher={Association for Computational Linguistics},
	author={Talat, Zeerak and Blix, Hagen and Valvoda, Josef and Ganesh, Maya Indira and Cotterell, Ryan and Williams, Adina},
	year={2022},
}

@article{thomson_trolley_1985,
	title={The {Trolley} {Problem}},
	volume={94},
	url={https://heinonline.org/HOL/Page?handle=hein.journals/ylr94&id=1415&div=&collection=},
	journal={Yale Law Journal},
	author={Thomson, Judith Jarvis},
	year={1985},
	note={numPages: 21},
	keywords={law, johan, jared\_not\_finished, trolley, stanford},
	pages={1395},
	file={The Trolley Problem Comment 94 Yale Law Journal 1984-1985:/Users/jared/Zotero/storage/FT83642P/LandingPage.html:text/html;Thomson - 1984 - The Trolley Problem.pdf:/Users/jared/Zotero/storage/9IHEMT5U/Thomson - 1984 - The Trolley Problem.pdf:application/pdf},
}

@book{buckner_deeply_2023,
	title={Deeply {Rational} {Machines}},
	publisher={Oxford University Press},
	author={Buckner, Cameron},
	year={2023},
	file={buckner_deeply_2023.pdf:/Users/jared/Zotero/storage/KADFNFV8/buckner_deeply_2023.pdf:application/pdf},
}

@article{simion_neoconstructivistic_2010,
	title={A neoconstructivistic approach to the emergence of a face processing system},
	journal={Neoconstructivism: The new science of cognitive development},
	author={Simion, Francesca and Leo, Irene},
	year={2010},
	note={Publisher: Oxford University Press Oxford},
	pages={314--332},
}

@incollection{johnson_kants_2022,
	edition={Fall 2022},
	title={Kant’s {Moral} {Philosophy}},
	url={https://plato.stanford.edu/archives/fall2022/entries/kant-moral/},
	abstract={Immanuel Kant (1724–1804) argued that the supreme principle ofmorality is a principle of practical rationality that he dubbed the“Categorical Imperative” (CI). Kant characterized the CIas an objective, rationally necessary and unconditional principle thatwe must follow despite any natural desires we may have to thecontrary. All specific moral requirements, according to Kant, arejustified by this principle, which means that all immoral actions areirrational because they violate the CI. Other philosophers, such asHobbes, Locke and Aquinas, had also argued that moral requirements arebased on standards of rationality. However, these standards wereeither instrumental principles of rationality for satisfyingone’s desires, as in Hobbes, or external rational principlesthat are discoverable by reason, as in Locke and Aquinas. Kant agreedwith many of his predecessors that an analysis of practical reasonreveals the requirement that rational agents must conform toinstrumental principles. Yet he also argued that conformity to the CI(a non-instrumental principle), and hence to moral requirementsthemselves, can nevertheless be shown to be essential to rationalagency. This argument was based on his striking doctrine that arational will must be regarded as autonomous, or free, in the sense ofbeing the author of the law that binds it. The fundamental principleof morality — the CI — is none other than the law of anautonomous will. Thus, at the heart of Kant’s moral philosophyis a conception of reason whose reach in practical affairs goes wellbeyond that of a Humean ‘slave’ to the passions. Moreover,it is the presence of this self-governing reason in each person thatKant thought offered decisive grounds for viewing each as possessed ofequal worth and deserving of equal respect.},
	urldate={2023-10-26},
	booktitle={The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher={Metaphysics Research Lab, Stanford University},
	author={Johnson, Robert and Cureton, Adam},
	editor={Zalta, Edward N. and Nodelman, Uri},
	year={2022},
	keywords={consequentialism, Kant, Immanuel, autonomy: personal, character, moral, consequentialism: rule, constructivism: in metaethics, ethics: deontological, ethics: virtue, Kant, Immanuel: account of reason, Kant, Immanuel: aesthetics and teleology, Kant, Immanuel: and Hume on morality, Kant, Immanuel: philosophical development, Kant, Immanuel: philosophy of religion, Kant, Immanuel: social and political philosophy, Kant, Immanuel: transcendental idealism, morality, definition of, practical reason, respect, rights},
	file={SEP - Snapshot:/Users/jared/Zotero/storage/ADMZ4JV9/kant-moral.html:text/html},
}

@article{bai_constitutional_2022,
	title={Constitutional ai: {Harmlessness} from ai feedback},
	journal={arXiv preprint arXiv:2212.08073},
	author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron},
	year={2022},
}

@article{fgts_cdb,
  author       = {Tong Zhang},
  title        = {Feel-Good Thompson Sampling for Contextual Bandits and Reinforcement
                  Learning},
  journal      = {CoRR},
  volume       = {abs/2110.00871},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.00871},
  eprinttype    = {arXiv},
  eprint       = {2110.00871},
  timestamp    = {Wed, 08 Feb 2023 17:00:37 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-00871.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{liang_holistic_2023,
	title={Holistic {Evaluation} of {Language} {Models}},
	url={http://arxiv.org/abs/2211.09110},
	doi={10.48550/arXiv.2211.09110},
	abstract={Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what's missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios when possible (87.5\% of the time). This ensures metrics beyond accuracy don't fall to the wayside, and that trade-offs are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to analyze specific aspects (e.g. reasoning, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, 21 of which were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9\% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0\%: now all 30 models have been densely benchmarked on the same core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.},
	urldate={2023-11-03},
	publisher={arXiv},
	author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and Newman, Benjamin and Yuan, Binhang and Yan, Bobby and Zhang, Ce and Cosgrove, Christian and Manning, Christopher D. and Ré, Christopher and Acosta-Navas, Diana and Hudson, Drew A. and Zelikman, Eric and Durmus, Esin and Ladhak, Faisal and Rong, Frieda and Ren, Hongyu and Yao, Huaxiu and Wang, Jue and Santhanam, Keshav and Orr, Laurel and Zheng, Lucia and Yuksekgonul, Mert and Suzgun, Mirac and Kim, Nathan and Guha, Neel and Chatterji, Niladri and Khattab, Omar and Henderson, Peter and Huang, Qian and Chi, Ryan and Xie, Sang Michael and Santurkar, Shibani and Ganguli, Surya and Hashimoto, Tatsunori and Icard, Thomas and Zhang, Tianyi and Chaudhary, Vishrav and Wang, William and Li, Xuechen and Mai, Yifan and Zhang, Yuhui and Koreeda, Yuta},
	month=oct,
	year={2023},
	note={arXiv:2211.09110 [cs]},
	keywords={Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file={arXiv Fulltext PDF:/Users/jared/Zotero/storage/9ASQKKS4/Liang et al. - 2023 - Holistic Evaluation of Language Models.pdf:application/pdf;arXiv.org Snapshot:/Users/jared/Zotero/storage/UJEYHGSU/2211.html:text/html},
}

@article{young_neurobiology_2004,
	title={The neurobiology of pair bonding},
	volume={7},
	copyright={2004 Springer Nature America, Inc.},
	issn={1546-1726},
	url={https://www.nature.com/articles/nn1327},
	doi={10.1038/nn1327},
	abstract={A neurobiological model for pair-bond formation has emerged from studies in monogamous rodents. The neuropeptides oxytocin and vasopressin contribute to the processing of social cues necessary for individual recognition. Mesolimbic dopamine is involved in reinforcement and reward learning. Concurrent activation of neuropeptide and dopamine receptors in the reward centers of the brain during mating results in a conditioned partner preference, observed as a pair bond. Differential regulation of neuropeptide receptor expression may explain species differences in the ability to form pair bonds. These and other studies discussed here have intriguing implications for the neurobiology of social attachment in our own species.},
	language={en},
	number={10},
	urldate={2023-11-03},
	journal={Nature Neuroscience},
	author={Young, Larry J. and Wang, Zuoxin},
	month=oct,
	year={2004},
	note={Number: 10
Publisher: Nature Publishing Group},
	keywords={Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, general, Neurobiology, Neurosciences},
	pages={1048--1054},
	file={Full Text PDF:/Users/jared/Zotero/storage/ARZH6LTK/Young and Wang - 2004 - The neurobiology of pair bonding.pdf:application/pdf},
}

@article{warneken_altruistic_2006,
	title={Altruistic helping in human infants and young chimpanzees},
	volume={311},
	number={5765},
	journal={science},
	author={Warneken, Felix and Tomasello, Michael},
	year={2006},
	note={ISBN: 0036-8075
Publisher: American Association for the Advancement of Science},
	pages={1301--1303},
}

@incollection{driver_history_2022,
	edition={Winter 2022},
	title={The {History} of {Utilitarianism}},
	url={https://plato.stanford.edu/archives/win2022/entries/utilitarianism-history/},
	abstract={Utilitarianism is one of the most powerful and persuasive approachesto normative ethics in the history of philosophy. Though notfully articulated until the 19th century, proto-utilitarianpositions can be discerned throughout the history of ethicaltheory.},
	urldate={2023-11-03},
	booktitle={The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher={Metaphysics Research Lab, Stanford University},
	author={Driver, Julia},
	editor={Zalta, Edward N. and Nodelman, Uri},
	year={2022},
	keywords={Bentham, Jeremy, consequentialism, hedonism, Hume, David, Mill, John Stuart, Moore, George Edward, Scottish Philosophy: in the 18th Century, Shaftesbury, Lord [Anthony Ashley Cooper, 3rd Earl of], Sidgwick, Henry, well-being},
	file={SEP - Snapshot:/Users/jared/Zotero/storage/HDEZQXST/utilitarianism-history.html:text/html},
}

@article{moerland_emotion_2018,
  title={Emotion in reinforcement learning agents and robots: a survey},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={Machine Learning},
  volume={107},
  pages={443--480},
  year={2018},
  publisher={Springer}
}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Value Alignment Verification References Below
@inproceedings{brown2021value,
  title={Value alignment verification},
  author={Brown, Daniel S and Schneider, Jordan and Dragan, Anca and Niekum, Scott},
  booktitle={International Conference on Machine Learning},
  pages={1105--1115},
  year={2021},
  organization={PMLR}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}

@inproceedings{huang2018establishing,
  title={Establishing appropriate trust via critical states},
  author={Huang, Sandy H and Bhatia, Kush and Abbeel, Pieter and Dragan, Anca D},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3929--3936},
  year={2018},
  organization={IEEE}
}

@article{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Russell, Stuart J and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{sadigh2017active,
  title={Active preference-based learning of reward functions},
  author={Sadigh, Dorsa and Dragan, Anca and Sastry, Shankar and Seshia, Sanjit},
  year={2017}
}

@inproceedings{brown2019machine,
  title={Machine teaching for inverse reinforcement learning: Algorithms and applications},
  author={Brown, Daniel S and Niekum, Scott},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7749--7758},
  year={2019}
}

 @misc{enwiki:1185176830,
    author="{Wikipedia contributors}",
    title="AI alignment --- {Wikipedia}{,} The Free Encyclopedia",
    year="2023",
    url="https://en.wikipedia.org/w/index.php?title=AI_alignment&oldid=1185176830",
    note="[Online; accessed 16-November-2023]"
  }

@misc{ngo2023alignment,
      title={The alignment problem from a deep learning perspective}, 
      author={Richard Ngo and Lawrence Chan and Sören Mindermann},
      year={2023},
      eprint={2209.00626},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{christianoclarifying,
    title={Clarifying ``AI alignment''},
    author={Paul Christiano},
    year={2018},
    url={https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6}
}

@misc{shah2022goal,
      title={Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals}, 
      author={Rohin Shah and Vikrant Varma and Ramana Kumar and Mary Phuong and Victoria Krakovna and Jonathan Uesato and Zac Kenton},
      year={2022},
      eprint={2210.01790},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{specificationgaming,
    title="Specification gaming: the flip side of AI ingenuity",
    author="Victoria Krakovna and Jonathan Uesato and Vladimir Mikulik and Matthew Rahtz and Tom Everitt and Ramana Kumar and Zac Kenton and Jan Leike and Shane Legg",
    year="2020",
    url="https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/"
}



@misc{belmont,
  author={{The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research}},
  title={The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research},
  year={1979},
  howpublished={\url{https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/index.html}},
  note={Accessed: 2023-11-12}
}

@misc{tuskegee,
  author={{Centers for Disease Control and Prevention}},
  title={The U.S. Public Health Service Untreated Syphilis Study at Tuskegee},
  year={2023},
  howpublished={\url{https://www.cdc.gov/tuskegee/index.html}},
  note={Accessed: 2023-11-12}
}

@inproceedings{oliveira17:labinthewild,
  author={Oliveira, Nigini and Jun, Eunice and Croxson, Trevor and Gajos, Krzysztof Z. and Reinecke, Katharina},
  title={LabintheWild: How to Design Uncompensated, Feedback-driven Online Experiments},
  booktitle={Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
  series={CSCW '17 Companion},
  year={2017},
  isbn={978-1-4503-4688-7},
  location={Portland, Oregon, USA},
  pages={25--28},
  numpages={4},
    doi={10.1145/3022198.3023267},
  acmid={3023267},
  publisher={ACM},
  address={New York, NY, USA},
  abstract={We present LabintheWild, an online experiment platform that provides participants with the opportunity to learn about themselves and compare themselves to others. In the past four years, LabintheWild has attracted approximately 3.5 million participants of diverse ages and education levels who came from more than 200 countries and regions. Leveraging our experience with LabintheWild, we show how researchers can design engaging and robust online experiments that provide personalized feedback. In particular, our interactive tutorial highlights challenges and best-practice guidelines for designing volunteer-based online experiments for diverse participant samples.},
      }

@article{chowdhery_palm_2022,
	title={{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle={{PaLM}},
	url={http://arxiv.org/abs/2204.02311},
	abstract={Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).},
	language={en},
	urldate={2022-04-18},
	journal={arXiv:2204.02311 [cs]},
	author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month=apr,
	year={2022},
	note={arXiv: 2204.02311},
	keywords={Computer Science - Computation and Language},
	file={Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:/Users/jared/Zotero/storage/QQUR5PJP/Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:application/pdf},
}

@article{hardt_patterns_2021,
  title={Patterns, predictions, and actions: A story about machine learning},
  author={Hardt, Moritz and Recht, Benjamin},
  journal={arXiv preprint arXiv:2102.05242},
  year={2021}
}

@inproceedings{santurkar_whose_2023,
  title={Whose opinions do language models reflect?},
  author={Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  booktitle={International Conference on Machine Learning},
  pages={29971--30004},
  year={2023},
  organization={PMLR}
}

@misc{goodman_lampost_2022,
  title={LaMPost: Evaluation of an AI-assisted Writing Email Editor Prototype for Adults with Dyslexia},
  author={Goodman, Steven and Buehler, Erin and Clary, Patrick and Coenen, Andy and Donsbach, Aaron Michael and Horne, Tiffanie and Lahav, Michal and MacDonald, Bob and Michaels, Rain Breaw and Narayanan, Ajit and others},
  year={2022}
}

@inproceedings{papineni_bleu_2002,
	title={Bleu: a method for automatic evaluation of machine translation},
	booktitle={Proceedings of the 40th annual meeting of the {Association} for {Computational} {Linguistics}},
	author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	year={2002},
	pages={311--318},
}

@inproceedings{banerjee_meteor_2005,
	title={{METEOR}: {An} automatic metric for {MT} evaluation with improved correlation with human judgments},
	booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
	author={Banerjee, Satanjeev and Lavie, Alon},
	year={2005},
	pages={65--72},
}

@inproceedings{lin_rouge_2004,
	title={Rouge: {A} package for automatic evaluation of summaries},
	booktitle={Text summarization branches out},
	author={Lin, Chin-Yew},
	year={2004},
	pages={74--81},
}

@article{xiong_achieving_2016,
	title={Achieving human parity in conversational speech recognition},
	journal={arXiv preprint arXiv:1610.05256},
	author={Xiong, Wayne and Droppo, Jasha and Huang, Xuedong and Seide, Frank and Seltzer, Mike and Stolcke, Andreas and Yu, Dong and Zweig, Geoffrey},
	year={2016},
}

@misc{lambert2023history,
      title={The History and Risks of Reinforcement Learning and Human Feedback}, 
      author={Nathan Lambert and Thomas Krendl Gilbert and Tom Zick},
      year={2023},
      eprint={2310.13595},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{bai2022constitutional,
    title={Constitutional AI: Harmlessness from AI Feedback}, 
    author={Yuntao Bai et al.},
    year={2022},
    eprint={2212.08073},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{mismatch,
    title={The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback}, 
    author={Nathan Lambert and R. Calandra},
    year={2023},
    eprint={2311.00168},
    archivePrefix={arXiv},
    primaryClass={cs.CY}
}

@misc{created-in-pres,
      title={Reinforcement Learning from Human Feedback}, 
      author={Nathan Lambert}, 
      year={2023},
}

@misc{stiennon2022learning,
      title={Learning to summarize from human feedback}, 
      author={Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
      year={2022},
      eprint={2009.01325},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ziegler2020finetuning,
      title={Fine-Tuning Language Models from Human Preferences}, 
      author={Daniel M. Ziegler and Nisan Stiennon and Jeffrey Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
      year={2020},
      eprint={1909.08593},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{leike2018scalable,
      title={Scalable agent alignment via reward modeling: a research direction}, 
      author={Jan Leike and David Krueger and Tom Everitt and Miljan Martic and Vishal Maini and Shane Legg},
      year={2018},
      eprint={1811.07871},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{Tamer,
  author={Bradley Knox, W. and Stone, Peter},
  booktitle={2008 7th IEEE International Conference on Development and Learning}, 
  title={TAMER: Training an Agent Manually via Evaluative Reinforcement}, 
  year={2008},
  volume={},
  number={},
  pages={292-297},
  doi={10.1109/DEVLRN.2008.4640845}
}

@article{DBLP:journals/corr/MansourSS15,
  author      ={Yishay Mansour and
                  Aleksandrs Slivkins and
                  Vasilis Syrgkanis},
  title       ={Bayesian Incentive-Compatible Bandit Exploration},
  journal     ={CoRR},
  volume      ={abs/1502.04147},
  year        ={2015},
  url         ={http://arxiv.org/abs/1502.04147},
  eprinttype   ={arXiv},
  eprint      ={1502.04147},
  timestamp   ={Mon, 13 Aug 2018 16:48:23 +0200},
  biburl      ={https://dblp.org/rec/journals/corr/MansourSS15.bib},
  bibsource   ={dblp computer science bibliography, https://dblp.org}
}
@misc{DBLP,
  author      ={Vasilis Syrgkanis},
  title       ={Incentivizing Exploration and
Compliance without Money},
  year        ={2023},
  url         ={https://web.stanford.edu/class/cs329h/slides/cs329h-lec12.pdf},
howpublished={\url{https://web.stanford.edu/class/cs329h/slides/cs329h-lec12.pdf}}
}

@misc{myers2021learning,
      title={Learning Multimodal Rewards from Rankings}, 
      author={Vivek Myers and Erdem Bıyık and Nima Anari and Dorsa Sadigh},
      year={2021},
      eprint={2109.12750},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kwon2021targeted,
      title={Targeted Data Acquisition for Evolving Negotiation Agents}, 
      author={Minae Kwon and Siddharth Karamcheti and Mariano-Florentino Cuellar and Dorsa Sadigh},
      year={2021},
      eprint={2106.07728},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@InProceedings{pmlr-v87-biyik18a,
  title=	 {Batch Active Preference-Based Learning of Reward Functions},
  author=      {Biyik, Erdem and Sadigh, Dorsa},
  booktitle=	 {Proceedings of The 2nd Conference on Robot Learning},
  pages=	 {519--528},
  year=	 {2018},
  editor=	 {Billard, Aude and Dragan, Anca and Peters, Jan and Morimoto, Jun},
  volume=	 {87},
  series=	 {Proceedings of Machine Learning Research},
  month=	 {29--31 Oct},
  publisher=   {PMLR},
  pdf=	 {http://proceedings.mlr.press/v87/biyik18a/biyik18a.pdf},
  url=	 {https://proceedings.mlr.press/v87/biyik18a.html},
  abstract=	 {Data generation and labeling are usually an expensive part of learning for robotics. While active learning methods are commonly used to tackle the former problem, preference-based learning is a concept that attempts to solve the latter by querying users with preference questions. In this paper, we will develop a new algorithm, batch active preference-based learning, that enables efficient learning of reward functions using as few data samples as possible while still having short query generation times. We introduce several approximations to the batch active learning problem, and provide theoretical guarantees for the convergence of our algorithms. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that are computed in a short amount of time. We then showcase our algorithm in a study to learn human users’ preferences. }
}

@inproceedings{Li_2021,
   title={ROIAL: Region of Interest Active Learning for Characterizing Exoskeleton Gait Preference Landscapes},
   url={http://dx.doi.org/10.1109/ICRA48506.2021.9560840},
   DOI={10.1109/icra48506.2021.9560840},
   booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
   publisher={IEEE},
   author={Li, Kejun and Tucker, Maegan and Biyik, Erdem and Novoseller, Ellen and Burdick, Joel W. and Sui, Yanan and Sadigh, Dorsa and Yue, Yisong and Ames, Aaron D.},
   year={2021},
   month=may }

@inproceedings{gandhi2022eliciting,
 title={Eliciting Compatible Demonstrations for Multi-Human Imitation Learning},
 author={Gandhi, Kanishk and Karamcheti, Siddharth and Liao, Madeline and Sadigh, Dorsa},
 booktitle={Proceedings of the 6th Conference on Robot Learning (CoRL)},
 year={2022}
}

@misc{bommasani2022opportunities,
      title={On the Opportunities and Risks of Foundation Models}, 
      author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
      year={2022},
      eprint={2108.07258},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{brohan2023rt2,
      title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control}, 
      author={Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich},
      year={2023},
      eprint={2307.15818},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{walke2023bridgedata,
      title={BridgeData V2: A Dataset for Robot Learning at Scale}, 
      author={Homer Walke and Kevin Black and Abraham Lee and Moo Jin Kim and Max Du and Chongyi Zheng and Tony Zhao and Philippe Hansen-Estruch and Quan Vuong and Andre He and Vivek Myers and Kuan Fang and Chelsea Finn and Sergey Levine},
      year={2023},
      eprint={2308.12952},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{nair2022r3m,
      title={R3M: A Universal Visual Representation for Robot Manipulation}, 
      author={Suraj Nair and Aravind Rajeswaran and Vikash Kumar and Chelsea Finn and Abhinav Gupta},
      year={2022},
      eprint={2203.12601},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{karamcheti2023languagedriven,
      title={Language-Driven Representation Learning for Robotics}, 
      author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
      year={2023},
      eprint={2302.12766},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
} 

@inproceedings{deng2009imagenet,
  title={ImageNet: A Large-Scale Hierarchical Image Database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009},
  organization={IEEE}
}

@inproceedings{he2020momentum,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9729--9738},
  year={2020},
  organization={IEEE}
}

@article{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@misc{grauman2022ego4d,
      title={Ego4D: Around the World in 3,000 Hours of Egocentric Video}, 
      author={Kristen Grauman and Andrew Westbury and Eugene Byrne and Zachary Chavis and Antonino Furnari and Rohit Girdhar and Jackson Hamburger and Hao Jiang and Miao Liu and Xingyu Liu and Miguel Martin and Tushar Nagarajan and Ilija Radosavovic and Santhosh Kumar Ramakrishnan and Fiona Ryan and Jayant Sharma and Michael Wray and Mengmeng Xu and Eric Zhongcong Xu and Chen Zhao and Siddhant Bansal and Dhruv Batra and Vincent Cartillier and Sean Crane and Tien Do and Morrie Doulaty and Akshay Erapalli and Christoph Feichtenhofer and Adriano Fragomeni and Qichen Fu and Abrham Gebreselasie and Cristina Gonzalez and James Hillis and Xuhua Huang and Yifei Huang and Wenqi Jia and Weslie Khoo and Jachym Kolar and Satwik Kottur and Anurag Kumar and Federico Landini and Chao Li and Yanghao Li and Zhenqiang Li and Karttikeya Mangalam and Raghava Modhugu and Jonathan Munro and Tullie Murrell and Takumi Nishiyasu and Will Price and Paola Ruiz Puentes and Merey Ramazanova and Leda Sari and Kiran Somasundaram and Audrey Southerland and Yusuke Sugano and Ruijie Tao and Minh Vo and Yuchen Wang and Xindi Wu and Takuma Yagi and Ziwei Zhao and Yunyi Zhu and Pablo Arbelaez and David Crandall and Dima Damen and Giovanni Maria Farinella and Christian Fuegen and Bernard Ghanem and Vamsi Krishna Ithapu and C. V. Jawahar and Hanbyul Joo and Kris Kitani and Haizhou Li and Richard Newcombe and Aude Oliva and Hyun Soo Park and James M. Rehg and Yoichi Sato and Jianbo Shi and Mike Zheng Shou and Antonio Torralba and Lorenzo Torresani and Mingfei Yan and Jitendra Malik},
      year={2022},
      eprint={2110.07058},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xiao2022masked,
      title={Masked Visual Pre-training for Motor Control}, 
      author={Tete Xiao and Ilija Radosavovic and Trevor Darrell and Jitendra Malik},
      year={2022},
      eprint={2203.06173},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{AL_app_autonomous,
  title={Active learning of driving scenario trajectories},
  author={Sanna Jarl and Linus Aronsson and Sadegh Rahrovani and Morteza Haghir Chehreghani},
  journal={Eng. Appl. Artif. Intell.},
  year={2021},
  volume={113},
  pages={104972},
  url={https://api.semanticscholar.org/CorpusID:249113683}
}

@article{AL_app_sensors,
  title={Active learning for adaptive mobile sensing networks},
  author={Aarti Singh and Robert D. Nowak and Parameswaran Ramanathan},
  journal={2006 5th International Conference on Information Processing in Sensor Networks},
  year={2006},
  pages={60-68},
  url={https://api.semanticscholar.org/CorpusID:17590956}
}

@article{AL_app_robotics,
  title={Active Learning in Robotics: A Review of Control Principles},
  author={Annalisa T. Taylor and Thomas A. Berrueta and Todd D. Murphey},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.13697},
  url={https://api.semanticscholar.org/CorpusID:235652039}
}

@article{AL_app_LLMs,
  title={Active Learning Principles for In-Context Learning with Large Language Models},
  author={Katerina Margatina and Timo Schick and Nikolaos Aletras and Jane Dwivedi-Yu},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.14264},
  url={https://api.semanticscholar.org/CorpusID:258841313}
}

@INPROCEEDINGS{AL_expmodelchange,
  author={Cai, Wenbin and Zhang, Ya and Zhou, Jun},
  booktitle={2013 IEEE 13th International Conference on Data Mining}, 
  title={Maximizing Expected Model Change for Active Learning in Regression}, 
  year={2013},
  volume={},
  number={},
  pages={51-60},
  doi={10.1109/ICDM.2013.104}}

@misc{AL_experrorredn,
      title={Active Learning with Expected Error Reduction}, 
      author={Stephen Mussmann and Julia Reisler and Daniel Tsai and Ehsan Mousavi and Shayne O'Brien and Moises Goldszmidt},
      year={2022},
      eprint={2211.09283},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{AL_variance,
  author      ={David A. Cohn and
                  Zoubin Ghahramani and
                  Michael I. Jordan},
  title       ={Active Learning with Statistical Models},
  journal     ={CoRR},
  volume      ={cs.AI/9603104},
  year        ={1996},
  url         ={https://arxiv.org/abs/cs/9603104},
  timestamp   ={Fri, 10 Jan 2020 12:58:04 +0100},
  biburl      ={https://dblp.org/rec/journals/corr/cs-AI-9603104.bib},
  bibsource   ={dblp computer science bibliography, https://dblp.org}
}

@article{AL_uncertainty,
  title={Active Learning With Sampling by Uncertainty and Density for Data Annotations},
  author={Jingbo Zhu and Huizhen Wang and Benjamin Ka-Yin T'sou and Matthew Y. Ma},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  year={2010},
  volume={18},
  pages={1323-1331},
  url={https://api.semanticscholar.org/CorpusID:5777911}
}

@article{AL_usercentered,
  title={Towards User‐Centered Active Learning Algorithms},
  author={J. Bernard and Matthias Zeppelzauer and Markus Lehmann and Martin M{\"u}ller and Michael Sedlmair},
  journal={Computer Graphics Forum},
  year={2018},
  volume={37},
  url={https://api.semanticscholar.org/CorpusID:51875861}
}

@inproceedings{AL_exploreexploit,
  title={Contextual Bandit for Active Learning: Active Thompson Sampling},
  author={Djallel Bouneffouf and Romain Laroche and Tanguy Urvoy and Rapha{\"e}l F{\'e}raud and Robin Allesiardo},
  booktitle={International Conference on Neural Information Processing},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:1701357}
}

@article{AL_committee,
  title={The Power of Ensembles for Active Learning in Image Classification},
  author={William H. Beluch and Tim Genewein and A. N{\"u}rnberger and Jan M. K{\"o}hler},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018},
  pages={9368-9377},
  url={https://api.semanticscholar.org/CorpusID:52838058}
}

@article{AL_partition,
  title={Partition-Based Active Learning for Graph Neural Networks},
  author={Jiaqi Ma and Ziqiao Ma and Joyce Chai and Qiaozhu Mei},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.09391},
  url={https://api.semanticscholar.org/CorpusID:246240846}
}

@article{AL_conformal,
  title={Active Learning Using Conformal Predictors: Application to Image Classification},
  author={L{\'a}zaro Em{\'i}lio Makili and Jes{\'u}s A. Vega S{\'a}nchez and Sebasti{\'a}n Dormido-Canto},
  journal={Fusion Science and Technology},
  year={2012},
  volume={62},
  pages={347 - 355},
  url={https://api.semanticscholar.org/CorpusID:115384000}
}

@article{AL_mismatch,
  title={Active Learning for Sound Event Detection},
  author={Shuyang Zhao and Toni Heittola and Tuomas Virtanen},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2020},
  volume={28},
  pages={2895-2905},
  url={https://api.semanticscholar.org/CorpusID:211082815}
}

@article{AL_BALD,
  title={Bayesian active learning for classification and preference learning},
  author={Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  journal={arXiv preprint arXiv:1112.5745},
  year={2011}
}

@article{geo_paper,
title={Active ranking using pairwise comparisons},
author={Jamieson Kevin G. and Robert Nowak},
journal={Advances in neural information processing systems},
volume={24},
year={2011},
}

@misc{ask_help,
    title={When to Ask for Help: Proactive Interventions in Autonomous Reinforcement Learning}, 
    author={Annie Xie and Fahim Tajwar and Archit Sharma and Chelsea Finn},
    year={2022},
    eprint={2210.10765},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2210.10765}, 
}

18 end. 20.1
@article{unnoisy_humans,
title={Power to the people: The role of humans in interactive machine learning},
author={Saleema Amershi and Maya Cakmak and W. Bradley Knox and Todd Kulesza},
journal={AI Magazine},
year={2014},
}

19. 20.2
@article{noisy_humans,
title={Simultaneous learning
and covering with adversarial noise},
author={Andrew Guillory and Jeff Bilmes},
journal={ICML},
year={2011},
}

20.3
@article{lus-shep,
title={Stimulus and response generalization: A stochastic model relating generalization to distance in psychological space},
author={Roger N Shepard},
journal={Psychometrika},
volume={22(4):325–345},
year={1957},
}

20.4
@article{lus-log,
title={Optimal bayesian recommendation sets and myopically optimal choice query sets},
author={Paolo Viappiani and Craig Boutilier},
journal={NIPS},
pages={2352-2360},
year={2010},
}

@article{claus,
    title={Active Comparison Based Learning Incorporating User Uncertainty and Noise},
    author={Rachel Holladay and Shervin Javdani and Anca Dragan and Siddhartha Srinivasa},
    journal={Proceedings of RSS '16 Workshop on Model Learning for Human-Robot Communication},
    year={2016},
}

@misc{max_halford,
    title={Online active learning in 80 lines of Python},
    author={Max Halford},
    year={2023},
}

@misc{spider,
      title={Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness}, 
      author={Shuaichen Chang and Jun Wang and Mingwen Dong and Lin Pan and Henghui Zhu and Alexander Hanbo Li and Wuwei Lan and Sheng Zhang and Jiarong Jiang and Joseph Lilien and Steve Ash and William Yang Wang and Zhiguo Wang and Vittorio Castelli and Patrick Ng and Bing Xiang},
      year={2023},
      eprint={2301.08881},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mv,
      title={Multi-VALUE: A Framework for Cross-Dialectal English NLP}, 
      author={Caleb Ziems and William Held and Jingfeng Yang and Jwala Dhamala and Rahul Gupta and Diyi Yang},
      year={2023},
      eprint={2212.08011},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dada,
      title={DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules}, 
      author={Yanchen Liu and William Held and Diyi Yang},
      year={2023},
      eprint={2305.13406},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{hovy-yang-2021-importance,
    title = "The Importance of Modeling Social Factors of Language: Theory and Practice",
    author = "Hovy, Dirk  and
      Yang, Diyi",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.49",
    doi = "10.18653/v1/2021.naacl-main.49",
    pages = "588--602",
}

@misc{hsu2023helping,
      title={Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback}, 
      author={Shang-Ling Hsu and Raj Sanjay Shah and Prathik Senthil and Zahra Ashktorab and Casey Dugan and Werner Geyer and Diyi Yang},
      year={2023},
      eprint={2305.08982},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@InProceedings{jasonH2023,
  title = 	 {Optimal Scoring Rules for Multi-dimensional Effort},
  author =       {Hartline, Jason D. and Shan, Liren and Li, Yingkai and Wu, Yifan},
  booktitle = 	 {Proceedings of Thirty Sixth Conference on Learning Theory},
  pages = 	 {2624--2650},
  year = 	 {2023},
  editor = 	 {Neu, Gergely and Rosasco, Lorenzo},
  volume = 	 {195},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v195/hartline23a/hartline23a.pdf},
  url = 	 {https://proceedings.mlr.press/v195/hartline23a.html},
  abstract = 	 {This paper develops a framework for the design of scoring rules to optimally incentivize an agent to exert a multi-dimensional effort. This framework is a generalization to strategic agents of the classical knapsack problem (cf. Briest, Krysta, and Vocking, 2005; Singer, 2010) and it is foundational to applying algorithmic mechanism design to the classroom. The paper identifies two simple families of scoring rules that guarantee constant approximations to the optimal scoring rule. The truncated separate scoring rule is the sum of single dimensional scoring rules that is truncated to the bounded range of feasible scores. The threshold scoring rule gives the maximum score if reports exceed a threshold and zero otherwise. Approximate optimality of one or the other of these rules is similar to the bundling or selling separately result of Babaioff, Immorlica, Lucier, and Weinberg (2014). Finally, we show that the approximate optimality of the best of those two simple scoring rules is robust when the agent’s choice of effort is made sequentially.}
}


@article{jasonH2020,
  author       = {Jason D. Hartline and
                  Yingkai Li and
                  Liren Shan and
                  Yifan Wu},
  title        = {Optimization of Scoring Rules},
  journal      = {CoRR},
  volume       = {abs/2007.02905},
  year         = {2020},
  url          = {https://arxiv.org/abs/2007.02905},
  eprinttype    = {arXiv},
  eprint       = {2007.02905},
  timestamp    = {Sat, 18 Jul 2020 18:41:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2007-02905.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bulow-klemperer1996,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/2118262},
 abstract = {Which is the more profitable way to sell a company: an auction with no reserve price or an optimally-structured negotiation with one less bidder? We show under reasonable assumptions that the auction is always preferable when bidders' signals are independent. For affiliated signals, the result holds under certain restrictions on the seller's choice of negotiating mechanism. The result suggests that the value of negotiating skill is small relative to the value of additional competition. The paper also shows how the analogies between monopoly theory and auction theory can help derive new results in auction theory.},
 author = {Jeremy Bulow and Paul Klemperer},
 journal = {The American Economic Review},
 number = {1},
 pages = {180--194},
 publisher = {American Economic Association},
 title = {Auctions Versus Negotiations},
 urldate = {2023-11-28},
 volume = {86},
 year = {1996}
}

@article{mcafee-87,
 ISSN = {00220515},
 URL = {http://www.jstor.org/stable/2726107},
 author = {R. Preston McAfee and John McMillan},
 journal = {Journal of Economic Literature},
 number = {2},
 pages = {699--738},
 publisher = {American Economic Association},
 title = {Auctions and Bidding},
 urldate = {2023-11-28},
 volume = {25},
 year = {1987}
}

@misc{monte-carlo,
      title={Sampling Algorithms, from Survey Sampling to Monte Carlo Methods: Tutorial and Literature Review}, 
      author={Benyamin Ghojogh and Hadi Nekoei and Aydin Ghojogh and Fakhri Karray and Mark Crowley},
      year={2020},
      eprint={2011.00901},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{bias_variance_orig_paper,
  title={Neural Networks and the Bias/Variance Dilemma},
  author={Stuart Geman and Elie Bienenstock and Ren{\'e} Doursat},
  journal={Neural Computation},
  year={1992},
  volume={4},
  pages={1-58},
  url={https://api.semanticscholar.org/CorpusID:14215320}
}

@article{bhatia2020preference,
  author={Bhatia, Kush and Pananjady, Ashwin and Bartlett, Peter L. and Dragan, Anca D. and Wainwright, Martin J.},
  title={Preference learning along multiple criteria: A game-theoretic perspective},
  journal={Neural Information Processing Systems},
  year={2020},
  volume={34},
  number={1},
  pages={1-12},
}

@article{keisler2003common,
  author={Keisler, H. Jerome and Lee, Byung Soo},
  title={Common Assumption of Rationality},
  journal={Economic Theory Journal},
  year={2003},
  volume={30},
  number={2},
  pages={123-145},
}

@article{miljkovic2005rational,
  author={Miljkovic, Dragan},
  title={Rational choice and irrational individuals or simply an irrational theory: A critical review of the hypothesis of perfect rationality},
  journal={The Journal of Socio-Economics},
  year={2005},
  volume={34},
  number={5},
  pages={621-634},
  doi={10.1016/j.socec.2003.12.031},
}

@incollection{simon1972theories,
  author={Simon, Herbert A.},
  title={Theories of Bounded Rationality},
  booktitle={Decision and Organization},
  editor={C.B. McGuire and Roy Radner},
  publisher={North-Holland Publishing Company},
  year={1972},
  pages={161-176},
}

@article{cattelan2012,
  author={Manuela Cattelan},
  title={Models for Paired Comparison Data: A Review with Emphasis on Dependent Data},
  journal={Statistical Science},
  year={2012},
  volume={27},
  number={3},
  pages={412-433},
  doi={10.1214/12-STS396}
}

@article{ragain2019,
  author={Ragain, Stephen and Ugander, Johan},
  title={Choosing to Rank},
  journal={arXiv preprint arXiv:1809.05139},
  year={2019},
  month={January},
  url={https://arxiv.org/abs/1809.05139}
}

@article{harpe2015,
  author={Harpe, Spencer E.},
  title={How to analyze Likert and other rating scale data},
  journal={Currents in Pharmacy Teaching and Learning},
  year={2015},
  volume={7},
  number={5},
  pages={836-850},
  url={http://dx.doi.org/10.1016/j.cptl.2015.08.001}
}

@article{campbell2015,
  author={Campbell, Danny and Erdem, Seda},
  title={Position Bias in Best-Worst Scaling Surveys: A Case Study on Trust in Institutions},
  journal={American Journal of Agricultural Economics},
  year={2015},
  volume={97},
  number={2},
  pages={526-545},
  doi={10.1093/ajae/aau112},
  url={https://doi.org/10.1093/ajae/aau112}
}

@article{rose2009,
  author={Rose, John M. and Hess, Stephane and Bliemer, Michiel C.J. and Daly, Andrew},
  title={The impact of varying the number of repeated choice observations on the mixed multinomial logit model},
  journal={Transportation Research Part B: Methodological},
  year={2009},
  volume={43},
  number={2},
  pages={e147-e155},
  url={https://doi.org/10.1016/j.trb.2008.05.003}
}

@article{bolt2009,
  author={Bolt, Daniel M. and Wollack, James A.},
  title={Application of a Multidimensional Nested Logit Model to Multiple-Choice Test Items},
  journal={Journal of Educational Measurement},
  year={2009},
  volume={46},
  number={3},
  pages={181-198},
  url={https://doi.org/10.1111/j.1745-3984.2009.00081.x}
}

@article{haase2011,
  author = {Haase, Steven J. and Fisk, Gary D.},
  title = {A Comparison of Signal Detection Theory to the Objective Threshold/Strategic Model of Unconscious Perception},
  journal = {Perceptual and Motor Skills},
  year = {2011},
  volume = {113},
  number = {1},
  pages = {242-256},
  doi = {10.2466/22.24.27.PMS.113.4.242-256}
}

@article{schwartz1992universals,
  title={Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries},
  author={Schwartz, Shalom H},
  journal={Advances in experimental social psychology},
  volume={25},
  pages={1--65},
  year={1992},
  publisher={Elsevier}
}

@book{frankena1973ethics,
  title={Ethics},
  author={Frankena, William K},
  year={1973},
  publisher={Prentice Hall}
}

@book{rawls1971theory,
  title={A Theory of Justice},
  author={Rawls, John},
  year={1971},
  publisher={Harvard University Press}
}

@book{dworkin1988theory,
  title={The Theory and Practice of Autonomy},
  author={Dworkin, Gerald},
  year={1988},
  publisher={Cambridge University Press}
}

@book{nussbaum1993quality,
  title={The Quality of Life},
  author={Nussbaum, Martha C and Sen, Amartya},
  year={1993},
  publisher={Oxford University Press}
}

@book{bostrom2014superintelligence,
  title={Superintelligence: Paths, Dangers, Strategies},
  author={Bostrom, Nick},
  year={2014},
  publisher={Oxford University Press}
}

@book{russell2019human,
  title={Human Compatible: Artificial Intelligence and the Problem of Control},
  author={Russell, Stuart},
  year={2019},
  publisher={Viking}
}

@book{floridi2011ethics,
  title={The Ethics of Information},
  author={Floridi, Luciano},
  year={2011},
  publisher={Oxford University Press}
}

@book{barocas_fairness_2019,
  title={Fairness and Machine Learning},
  author={Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year={2019},
  publisher={fairmlbook.org}
}

@book{oneil_weapons_2016,
  title={Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy},
  author={O'Neil, Cathy},
  year={2016},
  publisher={Crown Publishing Group}
}

@article{mehrabi_survey_2021,
  title={A Survey on Bias and Fairness in Machine Learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@book{noble_algorithms_2018,
  title={Algorithms of Oppression: How Search Engines Reinforce Racism},
  author={Noble, Safiya Umoja},
  year={2018},
  publisher={NYU Press}
}

@book{mill_utilitarianism_1863,
  title={Utilitarianism},
  author={Mill, John Stuart},
  year={1863},
  publisher={Parker, Son, and Bourn}
}

@book{aristotle_nicomachean_350,
  title={Nicomachean Ethics},
  author={Aristotle},
  year={350 B.C.E.},
  publisher={translated by W.D. Ross}
}

@inproceedings{binns_fairness_2018,
  title={Fairness in Machine Learning: Lessons from Political Philosophy},
  author={Binns, Reuben},
  booktitle={Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency},
  pages={149--159},
  year={2018}
}

@incollection{friedman_value_2008,
  title={Value Sensitive Design and Information Systems},
  author={Friedman, Batya and Kahn, Peter H. and Borning, Alan},
  booktitle={The Handbook of Information and Computer Ethics},
  year={2008},
  publisher={John Wiley \& Sons}
}

@incollection{muller_participatory_2003,
  title={Participatory Design: The Third Space in HCI},
  author={Muller, Michael J.},
  booktitle={The Human-Computer Interaction Handbook},
  year={2003},
  publisher={CRC Press}
}

@incollection{goodall_machine_2014,
  title={Machine Ethics and Automated Vehicles},
  author={Goodall, Noah J.},
  booktitle={Road Vehicle Automation},
  year={2014},
  pages={93--102},
  publisher={Springer}
}

@article{jiang_artificial_2017,
  title={Artificial Intelligence in Healthcare: Past, Present and Future},
  author={Jiang, Fei and Jiang, Yong and Zhi, Hang and Dong, Yuan and Li, Hui and Ma, Shugang and Wang, Yongan},
  journal={Stroke and Vascular Neurology},
  volume={2},
  number={4},
  pages={230--243},
  year={2017},
  publisher={BMJ}
}

@article{angwin_machine_2016,
  title={Machine Bias},
  author={Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  journal={ProPublica},
  year={2016}
}

@article{hubinger2019introduction,
  title={An Introduction to Inner Alignment},
  author={Hubinger, Evan and van Merwijk, Chris and Mikulik, Vladimir and Skalse, Joar and Garrabrant, Scott},
  journal={arXiv preprint arXiv:1906.01820},
  year={2019}
}

@article{krakovna2020specification,
  title={Specification Gaming Examples in AI},
  author={Krakovna, Victoria and others},
  journal={DeepMind Safety Research},
  year={2020}
}

@article{amodei2016concrete,
  title={Concrete Problems in AI Safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mane, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{everitt2018alignment,
  title={The Alignment Problem for Artificial Intelligence},
  author={Everitt, Tom and Hutter, Marcus},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1--8},
  year={2018}
}

@article{clark2016faulty,
  title={Faulty Reward Functions in the Wild},
  author={Clark, Jack and Amodei, Dario},
  journal={OpenAI Blog},
  year={2016}
}

@inproceedings{Morris2019HITL,
  title={Human-in-the-loop Computing: Reimagining Human-Computer Interaction in the Age of AI},
  author={Meredith Ringel Morris},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  year={2019},
  organization={ACM}
}

@inproceedings{bernstein2010soylent,
  title={Soylent: A Word Processor with a Crowd Inside},
  author={Michael S. Bernstein and Greg Little and Robert C. Miller and Bjorn Hartmann and Mark S. Ackerman and David R. Karger and David Crowell and Katrina Panovich},
  booktitle={Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology},
  year={2010},
  organization={ACM}
}

@inproceedings{lamport2017lampost,
  title={LaMPost: Leveraging Crowdsourcing for Natural Language Processing},
  author={LaMPort Project},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  year={2017},
  organization={ACL}
}

@book{dignum_responsible_2019,
  title={Responsible artificial intelligence: how to develop and use AI in a responsible way},
  author={Dignum, Virginia},
  volume={2156},
  year={2019},
  publisher={Springer}
}

@article{sap_socialIQA_2019,
  title={Socialiqa: Commonsense reasoning about social interactions},
  author={Sap, Maarten and Rashkin, Hannah and Chen, Derek and LeBras, Ronan and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09728},
  year={2019}
}

@book{ackley1987,
  author    = {David H. Ackley},
  title     = {A Connectionist Machine for Genetic Hillclimbing},
  publisher = {Kluwer Academic Publishers},
  year      = {1987},
  isbn      = {978-0-89838-247-9}
}

@incollection{mcfadden_conditional_1974,
  address   = {New York},
  title     = {Conditional Logit Analysis of Qualitative Choice Behavior},
  booktitle = {Frontiers in Econometrics},
  publisher = {Academic Press},
  author    = {McFadden, Daniel},
  editor    = {Zarembka, Paul},
  year      = {1974},
  pages     = {105--142}
}

@book{arrow1951,
  author = {Arrow, Kenneth J.},
  title = {Social Choice and Individual Values},
  publisher = {John Wiley and Sons},
  year = {1951}
}

@article{gibbard1973,
  author = {Gibbard, Allan},
  title = {Manipulation of voting schemes: A general result},
  journal = {Econometrica},
  volume = {41},
  number = {4},
  pages = {587--601},
  year = {1973},
  publisher = {JSTOR}
}

@article{satterthwaite1975,
  author = {Satterthwaite, Mark Allen},
  title = {Strategy-proofness and Arrow’s conditions: Existence and correspondence theorems for voting procedures and social welfare functions},
  journal = {Journal of Economic Theory},
  volume = {10},
  number = {2},
  pages = {187--217},
  year = {1975},
  publisher = {Elsevier}
}

@article{vickrey1961,
  author = {Vickrey, William},
  title = {Counterspeculation, Auctions, and Competitive Sealed Tenders},
  journal = {Journal of Finance},
  volume = {16},
  number = {1},
  pages = {8--37},
  year = {1961},
  publisher = {Wiley Online Library}
}

@article{myerson1981,
  author = {Myerson, Roger B.},
  title = {Optimal auction design},
  journal = {Mathematics of Operations Research},
  volume = {6},
  number = {1},
  pages = {58--73},
  year = {1981},
  publisher = {INFORMS}
}

@article{bartholdi1989,
  author = {Bartholdi, John J. and Tovey, Craig A. and Trick, Michael A.},
  title = {The computational difficulty of manipulating an election},
  journal = {Social Choice and Welfare},
  volume = {6},
  number = {3},
  pages = {227--241},
  year = {1989},
  publisher = {Springer}
}

@article{christiano2018supervising,
  author = {Christiano, Paul and Shlegeris, Buck and Amodei, Dario},
  title = {Supervising strong learners by amplifying weak experts},
  journal = {arXiv preprint arXiv:1810.08575},
  year = {2018}
}

@article{irving2018ai,
  author = {Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
  title = {AI safety via debate},
  journal = {arXiv preprint arXiv:1805.00899},
  year = {2018}
}

@inproceedings{gordon2022jury,
  author = {Gordon, Noah J. and Shankar, Vaishnavh Nagarajan and Feng, Shi and Choi, Yejin and Smith, Noah A.},
  title = {Jury Learning: Integrating Dissenting Voices into Machine Learning Models},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages = {2658--2673},
  year = {2022},
  publisher = {Association for Computational Linguistics}
}
